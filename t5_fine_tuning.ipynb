{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5_fine-tuning",
      "provenance": [],
      "collapsed_sections": [
        "HVxGfmEMCKs_",
        "RKNr7fgzcKpZ",
        "vfhlYUUV2NIh",
        "b3C13iabZvwK",
        "qdEgCwL7cIyi",
        "W4cfw8bMcNdA",
        "brPOSAkjNP5t",
        "Dhqigmiw2hVh",
        "0B4IhzEgO21B",
        "cANrUEXhO8QY",
        "DEWi6c-pGZV9",
        "GwdWdHG0RP5J",
        "iq8M8nbTSJlE",
        "vZ-YLmJyg64T",
        "hOxk-ZoJmamm",
        "aVfmE4O3Ku7H",
        "AgNV3TMzqSvj"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d8f60bfc0a248e58028b6e8a477a5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72dc1e39b931429883e68c0603797896",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cde60c5e18f04ba792fff8c2ac33f470",
              "IPY_MODEL_c0c0df12695b4a1eacf8fa4ccc0ac62c"
            ]
          }
        },
        "72dc1e39b931429883e68c0603797896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cde60c5e18f04ba792fff8c2ac33f470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72ea881ce3f445a9983d858b76dd257b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0f0c28a14b242f8990a547ed7f87c04"
          }
        },
        "c0c0df12695b4a1eacf8fa4ccc0ac62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f97741534b554be3b5cdccd45c73b317",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [02:08&lt;00:00, 6.18kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e70a3dc7090487fa883e932bff395cb"
          }
        },
        "72ea881ce3f445a9983d858b76dd257b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0f0c28a14b242f8990a547ed7f87c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f97741534b554be3b5cdccd45c73b317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e70a3dc7090487fa883e932bff395cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f414bac332054c7f86af89b8e50c7d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d9c52a1bb8843b6b0f151571cbf30a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed039b8125714030b03912fb29a93ca4",
              "IPY_MODEL_d9b445b8b3b04569adf22429259b4954"
            ]
          }
        },
        "1d9c52a1bb8843b6b0f151571cbf30a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed039b8125714030b03912fb29a93ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c61b3c76d7045eb825172ba51b3fa63",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d11ffd1efc024c1ca86276430d29fd1e"
          }
        },
        "d9b445b8b3b04569adf22429259b4954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22fac35d924f464ca0b33be21a566a86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:20&lt;00:00, 58.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfe128b0d2c648c18d2255b3f8506a09"
          }
        },
        "6c61b3c76d7045eb825172ba51b3fa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d11ffd1efc024c1ca86276430d29fd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22fac35d924f464ca0b33be21a566a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfe128b0d2c648c18d2255b3f8506a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c34ac6d2548249819c1eab28956edec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de2c77b3fb0f4dba99f92062b2db5328",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ea23f0979824aac935f3f1ad10a86cd",
              "IPY_MODEL_6452bc3b5ad445a8a5e272207fe4504d"
            ]
          }
        },
        "de2c77b3fb0f4dba99f92062b2db5328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ea23f0979824aac935f3f1ad10a86cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6ef508766c54f8993d1d1f3d7cac040",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b69bbddeb244defab9e21690a45c79e"
          }
        },
        "6452bc3b5ad445a8a5e272207fe4504d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a2b56fd6780470ab1574509fa432183",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:17&lt;00:00, 51.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3853231cd966465882a93fad9c5dc428"
          }
        },
        "d6ef508766c54f8993d1d1f3d7cac040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b69bbddeb244defab9e21690a45c79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a2b56fd6780470ab1574509fa432183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3853231cd966465882a93fad9c5dc428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "915a0b65612243668570c555a47a6c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c85b348624504af294b78de744969493",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d56a6918840e4f6588af5da5f8f54015",
              "IPY_MODEL_41db48cf488a4522b1f04b33c2261262"
            ]
          }
        },
        "c85b348624504af294b78de744969493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d56a6918840e4f6588af5da5f8f54015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c2d9ac8c22f486299949f4cbed16437",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_222974dba69145e7b171360bec239ba5"
          }
        },
        "41db48cf488a4522b1f04b33c2261262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e95200811bb497ab0ac0229f5e0ddaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:01&lt;00:00,  3.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3773b14f23974ad3a5bbb7ff947e68ca"
          }
        },
        "8c2d9ac8c22f486299949f4cbed16437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "222974dba69145e7b171360bec239ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e95200811bb497ab0ac0229f5e0ddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3773b14f23974ad3a5bbb7ff947e68ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ec26f803d124dd0877e1ce0e3517f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aabb0b2f2ae64684a80f1ea39c9a7d1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_885696e0606c4353a5d21feec03aebc7",
              "IPY_MODEL_659dd7302f3a40038834c4f1d8e59250"
            ]
          }
        },
        "aabb0b2f2ae64684a80f1ea39c9a7d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "885696e0606c4353a5d21feec03aebc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f3859c80aa945e4b4ae2aa957755b7c",
            "_dom_classes": [],
            "description": "Epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3125,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a840a738d20b4f43baf18453db53fdf0"
          }
        },
        "659dd7302f3a40038834c4f1d8e59250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7139c4e04374ffbafe6a849500c6369",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3125/3125 [54:28&lt;00:00,  1.05s/it, loss=0.003, v_num=0, val_loss=0.0874]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef8f0b7c9b0c4f829e3ad59e83cbdd67"
          }
        },
        "6f3859c80aa945e4b4ae2aa957755b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a840a738d20b4f43baf18453db53fdf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7139c4e04374ffbafe6a849500c6369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef8f0b7c9b0c4f829e3ad59e83cbdd67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbe7a4854b8f420faaea8de4583fb1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d1f674483d44e559ae1de553dd1d726",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce506c0137914e4db93b9db35154c62a",
              "IPY_MODEL_e92a181ff64d4e0290236a91cbdb8d67"
            ]
          }
        },
        "4d1f674483d44e559ae1de553dd1d726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ce506c0137914e4db93b9db35154c62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8f7179c238e4d2d91d456b2c07e1b3e",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e67100d71b5047158ab48ef0fd36cb99"
          }
        },
        "e92a181ff64d4e0290236a91cbdb8d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17f7e321de81404dabaa3e84fadce2cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [00:52&lt;00:00,  4.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a15e2fcc467242cb9fad5b2082a70c39"
          }
        },
        "e8f7179c238e4d2d91d456b2c07e1b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e67100d71b5047158ab48ef0fd36cb99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17f7e321de81404dabaa3e84fadce2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a15e2fcc467242cb9fad5b2082a70c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f40c9bf16c9a473ba758a6439dce2652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8d17a251bf1440d4aa8513ad5f15ba1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_165319529b364183ae344a9a14f5bc52",
              "IPY_MODEL_3d0c08f3abbe421d83f2b35583221291"
            ]
          }
        },
        "8d17a251bf1440d4aa8513ad5f15ba1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "165319529b364183ae344a9a14f5bc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e851577f682494c894b9afdd07b1201",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e67e9e945a9c430f9844946cd81aae3a"
          }
        },
        "3d0c08f3abbe421d83f2b35583221291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34fbc6e29df046faaedd9fe3230559cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [00:53&lt;00:00,  4.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbbdd81a2e8f4d68b33d698f45ccc9ae"
          }
        },
        "6e851577f682494c894b9afdd07b1201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e67e9e945a9c430f9844946cd81aae3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34fbc6e29df046faaedd9fe3230559cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbbdd81a2e8f4d68b33d698f45ccc9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6aaf51cb9ad44c94b6a174a8768904f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51d23e1199274477a69557c74609afb2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_029f74818c6842d7a28af62032418880",
              "IPY_MODEL_8db144e9144141779a1088c4bc000a99"
            ]
          }
        },
        "51d23e1199274477a69557c74609afb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "029f74818c6842d7a28af62032418880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_210517aede4f4cfab9120fdeb3d8361a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 782,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 782,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df9bc2dc2b3c4fee98affdd7f5ca1ef6"
          }
        },
        "8db144e9144141779a1088c4bc000a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b684a47485af4cb1934d57cbb03a4f57",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 782/782 [10:38&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_942d20b134964d1d895af69938918464"
          }
        },
        "210517aede4f4cfab9120fdeb3d8361a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df9bc2dc2b3c4fee98affdd7f5ca1ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b684a47485af4cb1934d57cbb03a4f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "942d20b134964d1d895af69938918464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c913726332c4bff99e5307b817b4e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e50a976c7a6345999923a56a97bef614",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd86a1eadb4f403381b6d7d5588766b5",
              "IPY_MODEL_57ac8ec882964d0dbf9289400ffaa1a0"
            ]
          }
        },
        "e50a976c7a6345999923a56a97bef614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "fd86a1eadb4f403381b6d7d5588766b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20231777aa164a9d8dac3d5a4cc55b63",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcbc6408637240f8b580ab2cf3c24dbb"
          }
        },
        "57ac8ec882964d0dbf9289400ffaa1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2684d80a827418db858dca73dd30c52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:01&lt;00:00,  4.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06d4184cb4c14f479712a64dd987ea19"
          }
        },
        "20231777aa164a9d8dac3d5a4cc55b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcbc6408637240f8b580ab2cf3c24dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2684d80a827418db858dca73dd30c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06d4184cb4c14f479712a64dd987ea19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcdd867494b641afb4975d99c2bdeac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a69f5b095c7f479e8d17e127676c8396",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75b6c7b980ca4c809d2e6d7879fca204",
              "IPY_MODEL_ec3768be32944b35b68bba180b4d0976"
            ]
          }
        },
        "a69f5b095c7f479e8d17e127676c8396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "75b6c7b980ca4c809d2e6d7879fca204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83411701a55a45a196989b6f1cb3717b",
            "_dom_classes": [],
            "description": "Epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2126,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2126,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c84be8af5614404bb615d387bba90556"
          }
        },
        "ec3768be32944b35b68bba180b4d0976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cea81db3622e4a3f884187664e271309",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2126/2126 [19:57&lt;00:00,  1.78it/s, loss=0.012, v_num=7, val_loss=0.88]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b15b28efba142488f3ace40c672fded"
          }
        },
        "83411701a55a45a196989b6f1cb3717b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c84be8af5614404bb615d387bba90556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cea81db3622e4a3f884187664e271309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b15b28efba142488f3ace40c672fded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b8815f08bb64ae784aef7c4f0b41a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_daf020ca7c564da1abaa066331a3ef96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8aebd9fbba2d4aaa938b50d9f3beb025",
              "IPY_MODEL_a5c67e852c3a42a2a249b298245f93dc"
            ]
          }
        },
        "daf020ca7c564da1abaa066331a3ef96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8aebd9fbba2d4aaa938b50d9f3beb025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce997619a8f14db684b84571e2d61380",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17bff8c40191450cb9ac056f732c3f60"
          }
        },
        "a5c67e852c3a42a2a249b298245f93dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd61fd8370a1451287a28f4b0060bb5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 126/126 [00:23&lt;00:00,  6.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf7a19930c434276bb322c8b40d57e27"
          }
        },
        "ce997619a8f14db684b84571e2d61380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17bff8c40191450cb9ac056f732c3f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd61fd8370a1451287a28f4b0060bb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf7a19930c434276bb322c8b40d57e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "336657cff8ad4cf5b0981b5d24e55085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_833981e781804953a8b3cddfb3249cb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c65ef68e147f405e97f0f5df29211f6b",
              "IPY_MODEL_d68af589009848089403dfc5fc2cc73a"
            ]
          }
        },
        "833981e781804953a8b3cddfb3249cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "c65ef68e147f405e97f0f5df29211f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51c575b1e58e41fdb9c202d128684b5c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13f48421b53d4b20b26fc0a58d5ea52f"
          }
        },
        "d68af589009848089403dfc5fc2cc73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e820cac698fa4152b9d7cfdb01ad0dd8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 126/126 [00:23&lt;00:00,  6.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ffbb7a6007041f487df2b87136472b9"
          }
        },
        "51c575b1e58e41fdb9c202d128684b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13f48421b53d4b20b26fc0a58d5ea52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e820cac698fa4152b9d7cfdb01ad0dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ffbb7a6007041f487df2b87136472b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53dba40d2405456e8c2dfb64bc4a6e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68b5668ca62f4499aa28e2159ae724a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_240fb77561064fa9bd3f3b4a5932feb1",
              "IPY_MODEL_b48e067c2b25477b98a749b73019acdc"
            ]
          }
        },
        "68b5668ca62f4499aa28e2159ae724a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "240fb77561064fa9bd3f3b4a5932feb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6319343ad9a442d91b044d88effd98a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 32,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9b23d64e3a34e9bb1c4d8030027da99"
          }
        },
        "b48e067c2b25477b98a749b73019acdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7702692d80cf45f9a3684935775d2a0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32/32 [00:44&lt;00:00,  1.40s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83308db5dd4b418498116f5539a81216"
          }
        },
        "e6319343ad9a442d91b044d88effd98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9b23d64e3a34e9bb1c4d8030027da99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7702692d80cf45f9a3684935775d2a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83308db5dd4b418498116f5539a81216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78b1b91a08214461b74fb1e143247d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_902a509471004d2691d807c4990fccd2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74ec15497e1743a4af6be12e3bc1487d",
              "IPY_MODEL_a70b457d9379403f9fac247de68bb8e3"
            ]
          }
        },
        "902a509471004d2691d807c4990fccd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74ec15497e1743a4af6be12e3bc1487d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28f9d9aa0ece4831b0f9e412d8a88f8d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7640680e1006492da75d873726567fed"
          }
        },
        "a70b457d9379403f9fac247de68bb8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1090e3e017564a2281c60fb53a901c75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:04&lt;00:00, 191kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9df2679ba627444e9b76bd2ff0ddc657"
          }
        },
        "28f9d9aa0ece4831b0f9e412d8a88f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7640680e1006492da75d873726567fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1090e3e017564a2281c60fb53a901c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9df2679ba627444e9b76bd2ff0ddc657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c7427d7db844b9691d30cf2de1efc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb0df1833ee3489da5c2a9c7b1306cc6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d2817812b6f475a8c838fd14646469a",
              "IPY_MODEL_9d0f0c946790477fb8bc8bac64dfd7de"
            ]
          }
        },
        "bb0df1833ee3489da5c2a9c7b1306cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d2817812b6f475a8c838fd14646469a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8254b8062d5e4280bea46f8bc444c5db",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab5f07ab5c574148a0062eb7f1ce5bcd"
          }
        },
        "9d0f0c946790477fb8bc8bac64dfd7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47fdc2009efc443392ecd182996fcca9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:42&lt;00:00, 28.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b705e83fea84cbf912e33d6342be721"
          }
        },
        "8254b8062d5e4280bea46f8bc444c5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab5f07ab5c574148a0062eb7f1ce5bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47fdc2009efc443392ecd182996fcca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b705e83fea84cbf912e33d6342be721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8e8ea6199df43019930ac7b557c46a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0566f29b017f47f399d7579d7929e046",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_932309f0a40b46659c0cac7cc37fdc05",
              "IPY_MODEL_da3665141bd44a24a5b5c9f36d4a9c52"
            ]
          }
        },
        "0566f29b017f47f399d7579d7929e046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "932309f0a40b46659c0cac7cc37fdc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c98e3a5b6a6403a936a725f4c30cdd3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8da2b560fa9348098a2a7f09967d5f5f"
          }
        },
        "da3665141bd44a24a5b5c9f36d4a9c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e37cac227014717987922341f8099fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:38&lt;00:00, 23.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b95f98f98a76434591f90d41b43e39ba"
          }
        },
        "5c98e3a5b6a6403a936a725f4c30cdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8da2b560fa9348098a2a7f09967d5f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e37cac227014717987922341f8099fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b95f98f98a76434591f90d41b43e39ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e79d03deee94b299431330441bd64c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_510043ffee634f86b89ec3fc060a74ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e86c5fbd48ce4215a0df353122183982",
              "IPY_MODEL_bfc3a5a3cf2e49868053db6f1ef7785d"
            ]
          }
        },
        "510043ffee634f86b89ec3fc060a74ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e86c5fbd48ce4215a0df353122183982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_361a2f79ed89495894d0b09a709f8f32",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7e53d55f0234627a3b9f2c90eb8682f"
          }
        },
        "bfc3a5a3cf2e49868053db6f1ef7785d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3584c01b0c5e47dfa373bae29461e94a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:01&lt;00:00,  3.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfd9db6f31474a8189e741bf8fdad6a9"
          }
        },
        "361a2f79ed89495894d0b09a709f8f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7e53d55f0234627a3b9f2c90eb8682f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3584c01b0c5e47dfa373bae29461e94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfd9db6f31474a8189e741bf8fdad6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68705cee3df5458fb5145046337d925c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4cf1613d58bd450780ac95c994686985",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ee5f7cf56394175900ebb14ae0b5f9e",
              "IPY_MODEL_9f054dcf926c45459b7aa728493571a0"
            ]
          }
        },
        "4cf1613d58bd450780ac95c994686985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3ee5f7cf56394175900ebb14ae0b5f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b52599dda9d94c83891d1c42c5f557e0",
            "_dom_classes": [],
            "description": "Epoch 3:   3%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 11694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 396,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1cf907a3bcc4177b1d5dd9edbf30c20"
          }
        },
        "9f054dcf926c45459b7aa728493571a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82b29ceeb21c417782e9e29a81eb47ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 396/11694 [03:40&lt;1:44:57,  1.79it/s, loss=0.017, v_num=0, val_loss=0.327]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_886260804ffd4e11bc93fb6e098111ab"
          }
        },
        "b52599dda9d94c83891d1c42c5f557e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1cf907a3bcc4177b1d5dd9edbf30c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82b29ceeb21c417782e9e29a81eb47ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "886260804ffd4e11bc93fb6e098111ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69f6eb1cb0434128961b5d83529813c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6723d50588a248d0ad7bb118de8c3fd5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86d71b8233c14252a897ffa29ea6d9df",
              "IPY_MODEL_d01c708e22ab423896271fa79860e7c3"
            ]
          }
        },
        "6723d50588a248d0ad7bb118de8c3fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "86d71b8233c14252a897ffa29ea6d9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e8da5995754472fac5fba1f8b30d107",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dbee77f299f4e14a1698b60d609b8a1"
          }
        },
        "d01c708e22ab423896271fa79860e7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c4c9025aaae44148591ae6f8bb37347",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2501/2501 [07:28&lt;00:00,  5.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29e2f2f0914e4dea8117844675b42be5"
          }
        },
        "0e8da5995754472fac5fba1f8b30d107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dbee77f299f4e14a1698b60d609b8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c4c9025aaae44148591ae6f8bb37347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29e2f2f0914e4dea8117844675b42be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cfc8fa73f164b4fa5ddcbc3f115ef9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4559bd35b33f4804b968debaaf316463",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e403cc7718bf48f1b95150482e083f02",
              "IPY_MODEL_f6248a9db7f2466a9ab3a4fbd214f265"
            ]
          }
        },
        "4559bd35b33f4804b968debaaf316463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e403cc7718bf48f1b95150482e083f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_475e5353d31147d3ab156c0e7835684c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3f65d683c6e4fe18e31ecc305f8d455"
          }
        },
        "f6248a9db7f2466a9ab3a4fbd214f265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b50abad66b44022aa389bc3f312db6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2501/2501 [07:25&lt;00:00,  5.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_762b2941ff3e47d89b6e6ce4350bc058"
          }
        },
        "475e5353d31147d3ab156c0e7835684c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3f65d683c6e4fe18e31ecc305f8d455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b50abad66b44022aa389bc3f312db6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "762b2941ff3e47d89b6e6ce4350bc058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1597779d89464892885045be715890a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a42468ed6b945e8bfce1803f3ea4452",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f87eae824cf1492b9555b78648a9f261",
              "IPY_MODEL_6cd0d574b5fd43588b8d492674125218"
            ]
          }
        },
        "8a42468ed6b945e8bfce1803f3ea4452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f87eae824cf1492b9555b78648a9f261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17b25142ac744ba882e2bbd1f42c1db2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 626,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 626,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09185d325ef84c1fad7b07fbd9eeed31"
          }
        },
        "6cd0d574b5fd43588b8d492674125218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba31765789dc46229493674dab21921d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 626/626 [06:35&lt;00:00,  1.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9dd88fb73374e108482b80993b998eb"
          }
        },
        "17b25142ac744ba882e2bbd1f42c1db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09185d325ef84c1fad7b07fbd9eeed31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba31765789dc46229493674dab21921d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9dd88fb73374e108482b80993b998eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJX4vkjj6wYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a837463a-35f0-46d9-eb20-3b3d1a9831e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V5cInhu42Wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154a5099-2168-417b-eea0-65f398d9aeba"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec 21 08:14:39 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epWcPHhJ7v7j"
      },
      "source": [
        "Instal apex if you want to do 16 bit training. You'll probably need to restart the notebook after installing apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Xy7ZG-7gHt"
      },
      "source": [
        "# !export CUDA_HOME=/usr/local/cuda-10.1\n",
        "# !git clone https://github.com/NVIDIA/apex\n",
        "# !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDVQ04fGRb1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19e6383-f51c-424b-f854-eff9bad74d4b"
      },
      "source": [
        "!pip install transformers==2.9.0\n",
        "!pip install pytorch_lightning==0.7.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.1.94)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
            "Requirement already satisfied: pytorch_lightning==0.7.5 in /usr/local/lib/python3.6/dist-packages (0.7.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (2.4.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (0.18.2)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (1.19.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning==0.7.5) (1.7.0+cu101)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (50.3.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_lightning==0.7.5) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_lightning==0.7.5) (0.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVxGfmEMCKs_"
      },
      "source": [
        "## T5 fine-tuning\n",
        "\n",
        "This notebook is to showcase how to fine-tune [T5 model](https://arxiv.org/abs/1910.10683) with Huggigface's [Transformers](https://github.com/huggingface/transformers/) to solve different NLP tasks using text-2-text approach proposed in the T5 paper. For demo I chose 3 non text-2-text problems just to reiterate the fact from the paper that how widely applicable this text-2-text framework is and how it can be used for different tasks without changing the model at all.\n",
        "\n",
        "This is a rough draft so if you find any issues with this notebook or have any  questions reach out to me via [Twitter](https://twitter.com/psuraj28).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS8mNXq6bdxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bceea0-f2dc-4de3-b0f6-5f9723a538d4"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:PyTorch version 1.7.0+cu101 available.\n",
            "INFO:transformers.file_utils:TensorFlow version 2.4.0 available.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IswYuhWaz7QJ"
      },
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKNr7fgzcKpZ"
      },
      "source": [
        "## Model\n",
        "\n",
        "We'll be using the awesome [pytorch-lightning](https://github.com/PytorchLightning/pytorch-lightning) library for training. Most of the below code is adapted from here https://github.com/huggingface/transformers/blob/master/examples/lightning_base.py\n",
        "\n",
        "The trainer is generic and can be used for any text-2-text task. You'll just need to change the dataset. Rest of the code will stay unchanged for all the tasks.\n",
        "\n",
        "This is the most intresting and powrfull thing about the text-2-text format. You can fine-tune the model on variety of NLP tasks by just formulating the problem in text-2-text setting. No need to change hyperparameters, learning rate, optimizer or loss function. Just plug in your dataset and you are ready to go!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7uVNBtXST5X"
      },
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, hparams):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.hparams = hparams\n",
        "    \n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "  \n",
        "  def is_logger(self):\n",
        "    return self.trainer.proc_rank <= 0\n",
        "  \n",
        "  def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "  ):\n",
        "    return self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        lm_labels=lm_labels,\n",
        "    )\n",
        "\n",
        "  def _step(self, batch):\n",
        "    lm_labels = batch[\"target_ids\"]\n",
        "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"source_ids\"],\n",
        "        attention_mask=batch[\"source_mask\"],\n",
        "        lm_labels=lm_labels,\n",
        "        decoder_attention_mask=batch['target_mask']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "\n",
        "    tensorboard_logs = {\"train_loss\": loss}\n",
        "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "  \n",
        "  def training_epoch_end(self, outputs):\n",
        "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "    return {\"val_loss\": loss}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "  \n",
        "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
        "    if self.trainer.use_tpu:\n",
        "      xm.optimizer_step(optimizer)\n",
        "    else:\n",
        "      optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "  \n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "    t_total = (\n",
        "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "        // self.hparams.gradient_accumulation_steps\n",
        "        * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1R5C-GwMqx"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "  def on_test_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Test results *****\")\n",
        "\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "\n",
        "      # Log and save results to file\n",
        "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "      with open(output_test_results_file, \"w\") as writer:\n",
        "        for key in sorted(metrics):\n",
        "          if key not in [\"log\", \"progress_bar\"]:\n",
        "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4hjvsBJ5Zk5"
      },
      "source": [
        "Let's define the hyperparameters and other arguments. You can overide this `dict` for specific task as needed. While in most of cases you'll only need to change the `data_dir`and `output_dir`.\n",
        "\n",
        "Here the batch size is 8 and gradient_accumulation_steps are 16 so the effective batch size is 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urduopvizqTq"
      },
      "source": [
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_seq_length=512,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=8,\n",
        "    eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    gradient_accumulation_steps=16,\n",
        "    n_gpu=1,\n",
        "    early_stop_callback=False,\n",
        "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
        "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
        "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
        "    seed=42,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfhlYUUV2NIh"
      },
      "source": [
        "## IMDB review classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3C13iabZvwK"
      },
      "source": [
        "### Download IMDB Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0QdcgXuIWW"
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xvf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni1cAK7EvXSB"
      },
      "source": [
        "train_pos_files = glob.glob('aclImdb/train/pos/*.txt')\n",
        "train_neg_files = glob.glob('aclImdb/train/neg/*.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEsRn5pa0v8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6977ce56-d0b4-4d9f-8548-22003bb07eaf"
      },
      "source": [
        "len(train_pos_files), len(train_neg_files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 12500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zgS8KhlaPiA"
      },
      "source": [
        "We will use 2000 samples from the train set for validation. Let's choose 1000 postive reviews and 1000 negative reviews for validation and save them in the val directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLvBHcXwzXrk"
      },
      "source": [
        "!mkdir aclImdb/val aclImdb/val/pos aclImdb/val/neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXZmLZ1pzjiY"
      },
      "source": [
        "random.shuffle(train_pos_files)\n",
        "random.shuffle(train_neg_files)\n",
        "\n",
        "val_pos_files = train_pos_files[:1000]\n",
        "val_neg_files = train_neg_files[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yTS2Jx40UNu"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJnJpkdb0ZKY"
      },
      "source": [
        "for f in val_pos_files:\n",
        "  shutil.move(f,  'aclImdb/val/pos')\n",
        "for f in val_neg_files:\n",
        "  shutil.move(f,  'aclImdb/val/neg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdEgCwL7cIyi"
      },
      "source": [
        "### Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McQC1FotigqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "7d8f60bfc0a248e58028b6e8a477a5f7",
            "72dc1e39b931429883e68c0603797896",
            "cde60c5e18f04ba792fff8c2ac33f470",
            "c0c0df12695b4a1eacf8fa4ccc0ac62c",
            "72ea881ce3f445a9983d858b76dd257b",
            "d0f0c28a14b242f8990a547ed7f87c04",
            "f97741534b554be3b5cdccd45c73b317",
            "1e70a3dc7090487fa883e932bff395cb"
          ]
        },
        "outputId": "f60dbf68-32cf-44e1-9a2f-f9dba38cbbac"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139780871368544 acquired on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpgy9lk1eo\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d8f60bfc0a248e58028b6e8a477a5f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model in cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n",
            "INFO:filelock:Lock 139780871368544 released on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wthd9SM74RG8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52deb6bd-19c4-4071-8bcb-254925d8e4cc"
      },
      "source": [
        "ids_neg = tokenizer.encode('negative </s>')\n",
        "ids_pos = tokenizer.encode('positive </s>')\n",
        "len(ids_neg), len(ids_pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5sJkyI3a723"
      },
      "source": [
        "All the examples are converted in the text-2-text format as shown in the paper. However I didn't use any task prefix here. The examples are encoded as follows,\n",
        "if the review is positive then the target is 'positive' else 'negative'\n",
        "\n",
        "**input**:  I went to see this\n",
        "movie with my husband, and we both\n",
        "thought the acting was terrible!\"\n",
        "\n",
        "**target**: negative\n",
        "\n",
        "**input**:  Despite what others say,\n",
        "I thought this movie was funny.\n",
        "\n",
        "**target**: positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYmYHKGcxEq"
      },
      "source": [
        "The dataset below takes care of reading the review files and processing the examples in text-2-text format.\n",
        "\n",
        "It cleans the review text by removing the html tags. It also appends the eos token `</s>` at the end of input and target as required by the T5 model \n",
        "\n",
        "For T5 max input length is 512 and we can choose the max length for target sequence depending upon our dataset. The `T5Tokenizer` encodes both 'postive' and 'negative' as a single ids so I chose the max target length 2, extra 1 for the `</s>` token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIY0GenSb72m"
      },
      "source": [
        "class ImdbDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
        "    self.pos_file_path = os.path.join(data_dir, type_path, 'pos')\n",
        "    self.neg_file_path = os.path.join(data_dir, type_path, 'neg')\n",
        "    \n",
        "    self.pos_files = glob.glob(\"%s/*.txt\" % self.pos_file_path)\n",
        "    self.neg_files = glob.glob(\"%s/*.txt\" % self.neg_file_path)\n",
        "    \n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self._build()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "  \n",
        "  def _build(self):\n",
        "    self._buil_examples_from_files(self.pos_files, 'positive')\n",
        "    self._buil_examples_from_files(self.neg_files, 'negative')\n",
        "  \n",
        "  def _buil_examples_from_files(self, files, sentiment):\n",
        "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "\n",
        "    for path in files:\n",
        "      with open(path, 'r') as f:\n",
        "        text = f.read()\n",
        "      \n",
        "      line = text.strip()\n",
        "      line = REPLACE_NO_SPACE.sub(\"\", line) \n",
        "      line = REPLACE_WITH_SPACE.sub(\"\", line)\n",
        "      line = line + ' </s>'\n",
        "\n",
        "      target = sentiment + \" </s>\"\n",
        "\n",
        "       # tokenize inputs\n",
        "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "          [line], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "       # tokenize targets\n",
        "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "          [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "      self.inputs.append(tokenized_inputs)\n",
        "      self.targets.append(tokenized_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsnsKY6jemsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98885b84-7f65-4d79-b470-619def772505"
      },
      "source": [
        "dataset = ImdbDataset(tokenizer, 'aclImdb', 'val',  max_len=512)\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g1gz05ccAzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b3a263f1-8b22-46bf-9a33-f58c996d684a"
      },
      "source": [
        "data = dataset[28]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To quote Flik that was my reaction exactly Wowyoure perfect This is the best movie I think I can even say its become my favorite movie ever even Wow I tell you what wow\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4cfw8bMcNdA"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTvkv4rzhPjy"
      },
      "source": [
        "!mkdir -p t5_imdb_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5ngAP4OXFqZ"
      },
      "source": [
        "args_dict.update({'data_dir': 'aclImdb', 'output_dir': 't5_imdb_sentiment', 'num_train_epochs':2})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJt_VqzEAMUg"
      },
      "source": [
        "Define the `get_dataset` function to return the dataset. The model calls this function to get the train and val datasets. We are defining a dataset function so that we won't need to modify the model code at all. Redefine the function to return different dataset according to the problem. While this is not the best solution for now this works "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h2aGPgp0vOf"
      },
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return ImdbDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IOQpawZA9XC"
      },
      "source": [
        "**Initialize model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJsz3a4SilAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f414bac332054c7f86af89b8e50c7d73",
            "1d9c52a1bb8843b6b0f151571cbf30a4",
            "ed039b8125714030b03912fb29a93ca4",
            "d9b445b8b3b04569adf22429259b4954",
            "6c61b3c76d7045eb825172ba51b3fa63",
            "d11ffd1efc024c1ca86276430d29fd1e",
            "22fac35d924f464ca0b33be21a566a86",
            "cfe128b0d2c648c18d2255b3f8506a09",
            "c34ac6d2548249819c1eab28956edec4",
            "de2c77b3fb0f4dba99f92062b2db5328",
            "6ea23f0979824aac935f3f1ad10a86cd",
            "6452bc3b5ad445a8a5e272207fe4504d",
            "d6ef508766c54f8993d1d1f3d7cac040",
            "1b69bbddeb244defab9e21690a45c79e",
            "4a2b56fd6780470ab1574509fa432183",
            "3853231cd966465882a93fad9c5dc428"
          ]
        },
        "outputId": "d711c5a7-4c7d-4392-8cf5-3df1cbcf2859"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139780702227256 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5_6vo8c2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f414bac332054c7f86af89b8e50c7d73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:filelock:Lock 139780702227256 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:transformers.configuration_utils:Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139780702189776 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
            "INFO:transformers.file_utils:https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmps92w5ati\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c34ac6d2548249819c1eab28956edec4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
            "INFO:filelock:Lock 139780702189776 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSJytKv1BFyc"
      },
      "source": [
        "**Initialize trainer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxO8OTA3irbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ebd7f3f-09fe-4363-9869-24d39183d2ff"
      },
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:GPU available: True, used: True\n",
            "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo7cSSvFGEhe"
      },
      "source": [
        "**start fine-tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVGd6imfizLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "915a0b65612243668570c555a47a6c37",
            "c85b348624504af294b78de744969493",
            "d56a6918840e4f6588af5da5f8f54015",
            "41db48cf488a4522b1f04b33c2261262",
            "8c2d9ac8c22f486299949f4cbed16437",
            "222974dba69145e7b171360bec239ba5",
            "9e95200811bb497ab0ac0229f5e0ddaa",
            "3773b14f23974ad3a5bbb7ff947e68ca",
            "3ec26f803d124dd0877e1ce0e3517f68",
            "aabb0b2f2ae64684a80f1ea39c9a7d1b",
            "885696e0606c4353a5d21feec03aebc7",
            "659dd7302f3a40038834c4f1d8e59250",
            "6f3859c80aa945e4b4ae2aa957755b7c",
            "a840a738d20b4f43baf18453db53fdf0",
            "f7139c4e04374ffbafe6a849500c6369",
            "ef8f0b7c9b0c4f829e3ad59e83cbdd67",
            "dbe7a4854b8f420faaea8de4583fb1f0",
            "4d1f674483d44e559ae1de553dd1d726",
            "ce506c0137914e4db93b9db35154c62a",
            "e92a181ff64d4e0290236a91cbdb8d67",
            "e8f7179c238e4d2d91d456b2c07e1b3e",
            "e67100d71b5047158ab48ef0fd36cb99",
            "17f7e321de81404dabaa3e84fadce2cf",
            "a15e2fcc467242cb9fad5b2082a70c39",
            "f40c9bf16c9a473ba758a6439dce2652",
            "8d17a251bf1440d4aa8513ad5f15ba1d",
            "165319529b364183ae344a9a14f5bc52",
            "3d0c08f3abbe421d83f2b35583221291",
            "6e851577f682494c894b9afdd07b1201",
            "e67e9e945a9c430f9844946cd81aae3a",
            "34fbc6e29df046faaedd9fe3230559cb",
            "bbbdd81a2e8f4d68b33d698f45ccc9ae"
          ]
        },
        "outputId": "cca18a5f-7900-4f58-ed74-6684b72a54e1"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "    | Name                                                                  | Type                       | Params\n",
            "-----------------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                                 | T5ForConditionalGeneration | 222 M \n",
            "1   | model.shared                                                          | Embedding                  | 24 M  \n",
            "2   | model.encoder                                                         | T5Stack                    | 109 M \n",
            "3   | model.encoder.block                                                   | ModuleList                 | 84 M  \n",
            "4   | model.encoder.block.0                                                 | T5Block                    | 7 M   \n",
            "5   | model.encoder.block.0.layer                                           | ModuleList                 | 7 M   \n",
            "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "22  | model.encoder.block.1                                                 | T5Block                    | 7 M   \n",
            "23  | model.encoder.block.1.layer                                           | ModuleList                 | 7 M   \n",
            "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "39  | model.encoder.block.2                                                 | T5Block                    | 7 M   \n",
            "40  | model.encoder.block.2.layer                                           | ModuleList                 | 7 M   \n",
            "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "56  | model.encoder.block.3                                                 | T5Block                    | 7 M   \n",
            "57  | model.encoder.block.3.layer                                           | ModuleList                 | 7 M   \n",
            "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "73  | model.encoder.block.4                                                 | T5Block                    | 7 M   \n",
            "74  | model.encoder.block.4.layer                                           | ModuleList                 | 7 M   \n",
            "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "90  | model.encoder.block.5                                                 | T5Block                    | 7 M   \n",
            "91  | model.encoder.block.5.layer                                           | ModuleList                 | 7 M   \n",
            "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "107 | model.encoder.block.6                                                 | T5Block                    | 7 M   \n",
            "108 | model.encoder.block.6.layer                                           | ModuleList                 | 7 M   \n",
            "109 | model.encoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "110 | model.encoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "111 | model.encoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "112 | model.encoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "113 | model.encoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "114 | model.encoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "115 | model.encoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "116 | model.encoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "117 | model.encoder.block.6.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "118 | model.encoder.block.6.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "119 | model.encoder.block.6.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "120 | model.encoder.block.6.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "122 | model.encoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "123 | model.encoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "124 | model.encoder.block.7                                                 | T5Block                    | 7 M   \n",
            "125 | model.encoder.block.7.layer                                           | ModuleList                 | 7 M   \n",
            "126 | model.encoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "127 | model.encoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "128 | model.encoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "129 | model.encoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "130 | model.encoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "131 | model.encoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "132 | model.encoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "133 | model.encoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "134 | model.encoder.block.7.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "135 | model.encoder.block.7.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "136 | model.encoder.block.7.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "137 | model.encoder.block.7.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "139 | model.encoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "140 | model.encoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "141 | model.encoder.block.8                                                 | T5Block                    | 7 M   \n",
            "142 | model.encoder.block.8.layer                                           | ModuleList                 | 7 M   \n",
            "143 | model.encoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "144 | model.encoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "145 | model.encoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "146 | model.encoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "147 | model.encoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "148 | model.encoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "149 | model.encoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "150 | model.encoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "151 | model.encoder.block.8.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "152 | model.encoder.block.8.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "153 | model.encoder.block.8.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "154 | model.encoder.block.8.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "156 | model.encoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "157 | model.encoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "158 | model.encoder.block.9                                                 | T5Block                    | 7 M   \n",
            "159 | model.encoder.block.9.layer                                           | ModuleList                 | 7 M   \n",
            "160 | model.encoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "161 | model.encoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "162 | model.encoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "163 | model.encoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "164 | model.encoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "165 | model.encoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "166 | model.encoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "167 | model.encoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "168 | model.encoder.block.9.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "169 | model.encoder.block.9.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "170 | model.encoder.block.9.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "171 | model.encoder.block.9.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "173 | model.encoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "174 | model.encoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "175 | model.encoder.block.10                                                | T5Block                    | 7 M   \n",
            "176 | model.encoder.block.10.layer                                          | ModuleList                 | 7 M   \n",
            "177 | model.encoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "178 | model.encoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "179 | model.encoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "180 | model.encoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "181 | model.encoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "182 | model.encoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "183 | model.encoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "184 | model.encoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "185 | model.encoder.block.10.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "186 | model.encoder.block.10.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "187 | model.encoder.block.10.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "188 | model.encoder.block.10.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "189 | model.encoder.block.10.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "190 | model.encoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "191 | model.encoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "192 | model.encoder.block.11                                                | T5Block                    | 7 M   \n",
            "193 | model.encoder.block.11.layer                                          | ModuleList                 | 7 M   \n",
            "194 | model.encoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "195 | model.encoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "196 | model.encoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "197 | model.encoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "198 | model.encoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "199 | model.encoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "200 | model.encoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "201 | model.encoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "202 | model.encoder.block.11.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "203 | model.encoder.block.11.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "204 | model.encoder.block.11.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "205 | model.encoder.block.11.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "206 | model.encoder.block.11.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "207 | model.encoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "208 | model.encoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "209 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "210 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
            "211 | model.decoder                                                         | T5Stack                    | 137 M \n",
            "212 | model.decoder.block                                                   | ModuleList                 | 113 M \n",
            "213 | model.decoder.block.0                                                 | T5Block                    | 9 M   \n",
            "214 | model.decoder.block.0.layer                                           | ModuleList                 | 9 M   \n",
            "215 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "216 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "217 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "218 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "219 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "220 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "222 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "223 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "224 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "225 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "226 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "227 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "228 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "229 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "230 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 384   \n",
            "231 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "232 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "233 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "234 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "235 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "236 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "237 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "238 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "239 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
            "240 | model.decoder.block.1                                                 | T5Block                    | 9 M   \n",
            "241 | model.decoder.block.1.layer                                           | ModuleList                 | 9 M   \n",
            "242 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "243 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "244 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "245 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "246 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "247 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "248 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "249 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "250 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "251 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "252 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "253 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "254 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "255 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "256 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "257 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "258 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "259 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "260 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "261 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "262 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "263 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "264 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
            "265 | model.decoder.block.2                                                 | T5Block                    | 9 M   \n",
            "266 | model.decoder.block.2.layer                                           | ModuleList                 | 9 M   \n",
            "267 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "268 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "269 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "270 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "271 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "272 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "273 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "274 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "275 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "276 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "277 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "278 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "279 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "280 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "281 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "282 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "283 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "284 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "285 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "286 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "287 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "288 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "289 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
            "290 | model.decoder.block.3                                                 | T5Block                    | 9 M   \n",
            "291 | model.decoder.block.3.layer                                           | ModuleList                 | 9 M   \n",
            "292 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "293 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "294 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "295 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "296 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "297 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "298 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "299 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "300 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "301 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "302 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "303 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "304 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "305 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "306 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "307 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "308 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "309 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "310 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "311 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "312 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "313 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "314 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
            "315 | model.decoder.block.4                                                 | T5Block                    | 9 M   \n",
            "316 | model.decoder.block.4.layer                                           | ModuleList                 | 9 M   \n",
            "317 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "318 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "319 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "320 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "321 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "322 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "323 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "324 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "325 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "326 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "327 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "328 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "329 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "330 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "331 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "332 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "333 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "334 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "335 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "336 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "337 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "338 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "339 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
            "340 | model.decoder.block.5                                                 | T5Block                    | 9 M   \n",
            "341 | model.decoder.block.5.layer                                           | ModuleList                 | 9 M   \n",
            "342 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "343 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "344 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "345 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "346 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "347 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "348 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "349 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "350 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "351 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "352 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "353 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "354 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "355 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "356 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "357 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "358 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "359 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "360 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "361 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "362 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "363 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "364 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
            "365 | model.decoder.block.6                                                 | T5Block                    | 9 M   \n",
            "366 | model.decoder.block.6.layer                                           | ModuleList                 | 9 M   \n",
            "367 | model.decoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "368 | model.decoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "369 | model.decoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "370 | model.decoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "371 | model.decoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "372 | model.decoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "373 | model.decoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "374 | model.decoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "375 | model.decoder.block.6.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "376 | model.decoder.block.6.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "377 | model.decoder.block.6.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "378 | model.decoder.block.6.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "379 | model.decoder.block.6.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "380 | model.decoder.block.6.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "381 | model.decoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "382 | model.decoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "383 | model.decoder.block.6.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "384 | model.decoder.block.6.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "385 | model.decoder.block.6.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "386 | model.decoder.block.6.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "387 | model.decoder.block.6.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "388 | model.decoder.block.6.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "389 | model.decoder.block.6.layer.2.dropout                                 | Dropout                    | 0     \n",
            "390 | model.decoder.block.7                                                 | T5Block                    | 9 M   \n",
            "391 | model.decoder.block.7.layer                                           | ModuleList                 | 9 M   \n",
            "392 | model.decoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "393 | model.decoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "394 | model.decoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "395 | model.decoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "396 | model.decoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "397 | model.decoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "398 | model.decoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "399 | model.decoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "400 | model.decoder.block.7.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "401 | model.decoder.block.7.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "402 | model.decoder.block.7.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "403 | model.decoder.block.7.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "404 | model.decoder.block.7.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "405 | model.decoder.block.7.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "406 | model.decoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "407 | model.decoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "408 | model.decoder.block.7.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "409 | model.decoder.block.7.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "410 | model.decoder.block.7.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "411 | model.decoder.block.7.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "412 | model.decoder.block.7.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "413 | model.decoder.block.7.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "414 | model.decoder.block.7.layer.2.dropout                                 | Dropout                    | 0     \n",
            "415 | model.decoder.block.8                                                 | T5Block                    | 9 M   \n",
            "416 | model.decoder.block.8.layer                                           | ModuleList                 | 9 M   \n",
            "417 | model.decoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "418 | model.decoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "419 | model.decoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "420 | model.decoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "421 | model.decoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "422 | model.decoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "423 | model.decoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "424 | model.decoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "425 | model.decoder.block.8.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "426 | model.decoder.block.8.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "427 | model.decoder.block.8.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "428 | model.decoder.block.8.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "429 | model.decoder.block.8.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "430 | model.decoder.block.8.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "431 | model.decoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "432 | model.decoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "433 | model.decoder.block.8.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "434 | model.decoder.block.8.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "435 | model.decoder.block.8.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "436 | model.decoder.block.8.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "437 | model.decoder.block.8.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "438 | model.decoder.block.8.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "439 | model.decoder.block.8.layer.2.dropout                                 | Dropout                    | 0     \n",
            "440 | model.decoder.block.9                                                 | T5Block                    | 9 M   \n",
            "441 | model.decoder.block.9.layer                                           | ModuleList                 | 9 M   \n",
            "442 | model.decoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "443 | model.decoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "444 | model.decoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "445 | model.decoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "446 | model.decoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "447 | model.decoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "448 | model.decoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "449 | model.decoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "450 | model.decoder.block.9.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "451 | model.decoder.block.9.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "452 | model.decoder.block.9.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "453 | model.decoder.block.9.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "454 | model.decoder.block.9.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "455 | model.decoder.block.9.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "456 | model.decoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "457 | model.decoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "458 | model.decoder.block.9.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "459 | model.decoder.block.9.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "460 | model.decoder.block.9.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "461 | model.decoder.block.9.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "462 | model.decoder.block.9.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "463 | model.decoder.block.9.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "464 | model.decoder.block.9.layer.2.dropout                                 | Dropout                    | 0     \n",
            "465 | model.decoder.block.10                                                | T5Block                    | 9 M   \n",
            "466 | model.decoder.block.10.layer                                          | ModuleList                 | 9 M   \n",
            "467 | model.decoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "468 | model.decoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "469 | model.decoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "470 | model.decoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "471 | model.decoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "472 | model.decoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "473 | model.decoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "474 | model.decoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "475 | model.decoder.block.10.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "476 | model.decoder.block.10.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "477 | model.decoder.block.10.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "478 | model.decoder.block.10.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "479 | model.decoder.block.10.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "480 | model.decoder.block.10.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "481 | model.decoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "482 | model.decoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "483 | model.decoder.block.10.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "484 | model.decoder.block.10.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "485 | model.decoder.block.10.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "486 | model.decoder.block.10.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "487 | model.decoder.block.10.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "488 | model.decoder.block.10.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "489 | model.decoder.block.10.layer.2.dropout                                | Dropout                    | 0     \n",
            "490 | model.decoder.block.11                                                | T5Block                    | 9 M   \n",
            "491 | model.decoder.block.11.layer                                          | ModuleList                 | 9 M   \n",
            "492 | model.decoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "493 | model.decoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "494 | model.decoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "495 | model.decoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "496 | model.decoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "497 | model.decoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "498 | model.decoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "499 | model.decoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "500 | model.decoder.block.11.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "501 | model.decoder.block.11.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "502 | model.decoder.block.11.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "503 | model.decoder.block.11.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "504 | model.decoder.block.11.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "505 | model.decoder.block.11.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "506 | model.decoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "507 | model.decoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "508 | model.decoder.block.11.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "509 | model.decoder.block.11.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "510 | model.decoder.block.11.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "511 | model.decoder.block.11.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "512 | model.decoder.block.11.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "513 | model.decoder.block.11.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "514 | model.decoder.block.11.layer.2.dropout                                | Dropout                    | 0     \n",
            "515 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "516 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
            "517 | model.lm_head                                                         | Linear                     | 24 M  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "915a0b65612243668570c555a47a6c37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ec26f803d124dd0877e1ce0e3517f68",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe7a4854b8f420faaea8de4583fb1f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_val_loss = tensor(0.0839, device='cuda:0')\n",
            "\n",
            "INFO:__main__:loss = tensor(0.0199, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.0199, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.0839, device='cuda:0')\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f40c9bf16c9a473ba758a6439dce2652",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_train_loss = tensor(0.2954, device='cuda:0')\n",
            "\n",
            "INFO:__main__:avg_val_loss = tensor(0.0874, device='cuda:0')\n",
            "\n",
            "INFO:__main__:epoch = 0\n",
            "\n",
            "INFO:__main__:loss = tensor(0.0066, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.0066, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.0874, device='cuda:0')\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-obOz6v70iB"
      },
      "source": [
        "!mkdir t5_base_imdb_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQBJcrrWi2vC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a98adf77-6e23-4304-8ccc-5b13a33a2a32"
      },
      "source": [
        "## save the model this way so next time you can load it using T5ForConditionalGeneration.from_pretrained\n",
        "model.model.save_pretrained('t5_base_imdb_sentiment')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:Configuration saved in t5_base_imdb_sentiment/config.json\n",
            "INFO:transformers.modeling_utils:Model weights saved in t5_base_imdb_sentiment/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhjELPOk7-cz"
      },
      "source": [
        "# !cp -r t5_base_imdb_sentiment drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brPOSAkjNP5t"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7SuVh05lDrJ"
      },
      "source": [
        "For inference we will use the `generate` method with greedy decoding with max length 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25jbT49CVoXN"
      },
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyriGR20lSRa"
      },
      "source": [
        "Let's visualize few predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJ998sMz2Ci"
      },
      "source": [
        "dataset = ImdbDataset(tokenizer, 'aclImdb', 'test',  max_len=512)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LQtN5b90TyW"
      },
      "source": [
        "it = iter(loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRD03teH0YMe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d43041e6-5d7d-49d5-e91a-7530c5d1d6b1"
      },
      "source": [
        "batch = next(it)\n",
        "batch[\"source_ids\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eewDktozk7GN"
      },
      "source": [
        "outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "dec = [tokenizer.decode(ids) for ids in outs]\n",
        "\n",
        "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
        "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vBe0UNw7cHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f0171ac-8d7d-41db-db31-d57bf72bc205"
      },
      "source": [
        "for i in range(32):\n",
        "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n",
        "    print(\"\\n\".join(lines))\n",
        "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
        "    print(\"Predicted sentiment: %s\" % dec[i])\n",
        "    print(\"=====================================================================\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: I dont know where to begin Perhaps the whole idea of this movie was just a disaster waiting\n",
            "to happen There is nothing slightly humorous about a kidnapping I dont know what was more\n",
            "offensivethe subject matter or David Arquettes performance It was like watching a bull get its penis\n",
            "cut off although I think the bull felt better afterwards The filmmakers should find something about\n",
            "Sinatra other than his sons kidnapping to show like I dont know his TALENT AS A SINGER His family\n",
            "shouldnt have to relive that horror Thank GOD it was just shown on HBO and not released in theaters\n",
            "Please dont watch this if you have any self respect\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: A fine performance by Vittorio Mezzogiorno and a masterful one by JeanHugues Anglade adorn\n",
            "this stange tale of lust desire and alienation in France The work of the two lead performers is\n",
            "strikingsubtle intense and passionate Alas the script is deliberately turgid and sordid and the\n",
            "overall effect leaves one with a downcast spirit Still those who can appreciate fine quality acting\n",
            "will be able to savor the courageous work of the leads in this often difficult film journey of\n",
            "Gallic low life\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: I almost stopped watching Hindi movies because of the mediocre quality and story lines One\n",
            "exception for this is Ramgopal Verma movies This is a nice movie with great performances from the\n",
            "star cast This is must see movie for those who are sick of watching stupid dancing and love stories\n",
            "The adaptation of the story and characterization was exceptional goodYou should watch this movie for\n",
            "Nana Patekar based on the life of Mumbai cop Daya Naik this movie deals in a more realistic way The\n",
            "film delves into the life of the common man which he has apart from being an encounter specialist I\n",
            "rate this as one of the best movie of the year\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: This was a really interesting Halloween film I wasnt to thrilled with the whole Thorn theory\n",
            "but it still makes for a good film I liked getting to see Tommy Doyle back but sadly Donald\n",
            "Pleasance died right after shooting The film had a really REALLY bad director who didnt give a flip\n",
            "about the series from what I heard treated Donald bad and wouldnt let Danielle Harris come back as\n",
            "Jamie Its like he was just trying to bring down the film but I still liked it There were alot of\n",
            "cuts and music changes and if youre lucky you can get the Producers Cut which features over 40 min\n",
            "of never before scenes With those scenes it turns into a whole new movie Check it out if you have\n",
            "the chance\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: Cheerleader Massacre was supposed to be the fourth installment of the Slumber Party Massacre\n",
            "series if thats what they were doing which it is considering ONE actress from the original returns\n",
            "in a small cameo role they have failed miserably and made by far the worst installment of the\n",
            "quadrilogy Cheerleader Massacre seamlessly combines bad acting a horrible plot a dumb killer dull\n",
            "and boring deaths boring scenery and hideous camera work to make it one of the worst films ever made\n",
            "Did I already mention how bad it was Dont get me wrong this cheesy and retarded excuse for a horror\n",
            "film is nowhere near as bad as Napoleon Dynamite but it is undeniably a horrible movieCheerleader\n",
            "Massacre is an exact polar opposite of the original Slumber Party Massacre Stay away by all means\n",
            "This movie is utter garbage\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: This movie will give me nightmares I will wake up drenched in sweat screaming I didnt make\n",
            "this film please dont blame me I honestly think it would have been more entertaining to watch a fat\n",
            "guy eating lard in his moms basement for a hour or two than to watch this crap I understand money\n",
            "was tight but goddamn what the hell were they thinking there was no thought plot or effort put into\n",
            "this This movie needs a warning Please for the love of god dont fund the drama department a the\n",
            "local JC On an other note these are the least likable characters I have ever seen and I have seen\n",
            "movies with Hitler in them So lastly take my advice the next time you even think about renting this\n",
            "just pop a few hundred Adivl and let the sleep come\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: In this movie Virtual Sexuality the 17 year old Justine is not lucky in love One day when\n",
            "she is stood up she goes with her friend to a virual reality conference there she is introduced with\n",
            "a machine that can change your look dody and whatever you like in Virtual Reality She decides to try\n",
            "it out but begins to make a boyfriend of her own her dreamdate Then suddenly there is an explosion\n",
            "in a gas pipe and her creation comes to life Ill say no more youll have to watch the movie which is\n",
            "quite fun to watch\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: Why does C Thomas Howell do these movies Cruise Howells one time costar does a huge\n",
            "blockbuster of WOTW and Howell follows with this lame effortWhere do I start here Production Values\n",
            "Ill start with the good stuff The look and feel of some of the scenes in this movie are not too bad\n",
            "to be honest The setups are okay in spots and the direction not too badScript Terrible A series of\n",
            "clunky scenes that could have been put in any order you like permeate throughout the movie The\n",
            "amount of times the scene faded to black and reemerged a second later in the same room was\n",
            "uncountable Very poor storyline but so was the Cruise WOTW takes some blame but an abysmal\n",
            "screenplay kills it offSpecial FX Okay I dont want to be too harsh here as I imagine the budget was\n",
            "smaller than Cruises lunch bill but in the overall context of the film the effects are badly done\n",
            "Some shots are quite impressive mainly far off destruction shots of bridges Washington liner But in\n",
            "the main the alien machines and tentacles themselves are dreadful Also the camera quality is fuzzy\n",
            "on some shots and cuts away entirely on othersActing Im a fan of Howell but as he has reduced\n",
            "himself to acting in these lowbudget flicks he has succumbed to the overacting bug a long time ago\n",
            "Look at his performance in The Hitcher and compare it to this movie There is no comparison He\n",
            "overdoes his facial expressions his flailing arms and legs where did he get that running style and\n",
            "for a final coupdegras look at the scene where he loses the photo of his family Hysterical But after\n",
            "saying all that he is still the best actor on show here Busey is embarrassing to look at and Peter\n",
            "Green Zed is truly dead now baby mumbles incoherently through his one and only scene I honestly\n",
            "could not understand one word he said I even went so far as trying to enable the subtitles on that\n",
            "scene but the DVD did not have subtitles This seems to be a real keepitinthefamily affair too as\n",
            "Howells son the directors wife and the line producer all make it into the film None of them are\n",
            "goodDirection not bad but not good eitherScore DismalOverall a lame duck effort that will don'thing\n",
            "for Howell in his\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: Another Asian horror movie packed with intense and creepy moments Another Asian horror\n",
            "trademark is the complexity of the plot which is here as well MAJOR SPOILER WARNINGThe movie starts\n",
            "pretty simple two sisters go to live with their dad and stepmother after being put in a mental\n",
            "institution after their mother hanged herself The sisters seem very hostile towards their mother\n",
            "especially the elder one and they seem to ignore their father All goes smoothly until the mother\n",
            "locks the young sister in the wardrobe and the elder sister tells her father Then it hits you your\n",
            "sister has been dead for years now It turns out the older sister is still not recovered from the\n",
            "death of her mother and what we didnt know is that the wardrobe the mother was hanged in fell on the\n",
            "younger sister and killed her as wellAs for the stepmother she is the alter ego of the older sister\n",
            "revealed when the stepmother actually the sisters alter ego is sitting on a couch when the real\n",
            "stepmother walks in I hope it has been made clearer for confused Asian horror fans out thereFinally\n",
            "my favourite scene is the scene where the father invites friends over for dinner and one of the\n",
            "friends starts to choke which erupts into a panic attack Very creepy 7 out of 10\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: As a native of New Orleans I can state that almost everything in this movie from the\n",
            "atrocious NAwlins dialect to the highly creative manipulation of Crescent City geography is horrible\n",
            "This is another one of those Big Hollywood movies that decides to stereotype New Orleans as 1 A city\n",
            "full of Frenchsounding idiots 2 A city full of people who sound as if theyve just returned from\n",
            "Blanche Dubois summer home 3 A city of drunkards where every day is Mardi Gras 4 A city of deep\n",
            "mystery where almost everyone practices or is a victim of voodoo I admit that maybe we are a city of\n",
            "drunkards although every day is NOT Mardi Gras The Big Easy is one of the worst films about New\n",
            "Orleans I wouldnt recommend it to anybody\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: This selfimportant confusing b+w film watches like an infant on a very bad acid trip Youre\n",
            "dealing with something that reminds you of a piece of rotting lettuce that accidentally fell out of\n",
            "the back of a garbage truck no one cares to touch it because it will probably be washed away on its\n",
            "own down the storm drain Theres no room for plot when youve got visceral imagery and subtle allegory\n",
            "To me it seems like the director tries to make the next great art movie while begging for\n",
            "intellectual accolades I didnt bring my beret either Watching this I felt almost insulted since the\n",
            "film does such an effective job of distancing itself from you\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: Mercy the movie actually starts out as a somewhat decent film and ellen barkin does give a\n",
            "strong performance But if you have read the book and actually got to know the characters and cared\n",
            "who done it the movie just does not compare It is always hard to brink a book onto film and\n",
            "unfortunatley this one ends up failing 3 out of 10\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: What in the world This piece of gambling cinema would have been suitable for the Lifetime\n",
            "Network Michael Imperoli is a good actor but I think his portrayal as Stu fell short The montages\n",
            "were unbearable and too many The supporting cast where are you Whoever did the casting should be\n",
            "partially at fault The cinematography was useless A gambling story with an after school feel to it\n",
            "Stories of this sort should be left for the Oliver Stones of the world It would still suck ass but\n",
            "at least it would be fun to watch It was an attempt that lost its wheels before the race ever begun\n",
            "Mario Andretti in the 1982 Indy 500 came to mind\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: This movie definitely made me laugh but that doesnt mean it was exactly funny Well then\n",
            "again me and my friends had a lot of fun watching itI doubt there is anything about this movie that\n",
            "hasnt been done at least twice before just like the plot itself All of the characters are overused\n",
            "movie cliché cardboardbox roles that dont even require acting skills accordingly such skills are not\n",
            "delivered We have the corrupt cop a ruthless killer who claims to care about his men and their\n",
            "families whilst caring nothing about people he shoots in the forehead at so close a range as to have\n",
            "blood spat on his face We have the wornout cop on the edge so nicely pointed at in the discussion\n",
            "boards of this movie we have the old onedayawayfromretirementcop who just about everyone must have\n",
            "immediately identified as the most likely man on the inside since he had most to gain and he didnt\n",
            "utter a trustworthy word throughout the movie About as seethrough as a glass house on a sunny day\n",
            "The big black gangster king was a copy of all previous big black gangster kings in movie history\n",
            "they couldve just called him Marcellus Wallace but just slightly tougher and more ruthless because\n",
            "something has to emphasize that we also know Laurence Fishburne from actually good movies Then we\n",
            "finally have the HIGHLY EDUCATED doctor who cant think of anything reasonable to do as soon as the\n",
            "situation differs from her ordinary life and who spends the majority of the movie sitting in a\n",
            "corner helplessly trying to figure out how to hold on to the weapon she was given NOT USING ITThe\n",
            "whole siege story is not interesting not original having been used twice before and this movie\n",
            "manages to add absolutely nothing interesting to it There is the initial probe then the laying of\n",
            "the siege then the assault then the escape attempts Meanwhile a bunch of strained stressed freaked\n",
            "out cops and thugs manage to hold off a Police assault team with hightech equipment and the quite\n",
            "important advantage of VISION Then again in deep night with the power cut and with a snow storm\n",
            "raging overhead there is definitely a lot of light coming in so who really cares about night\n",
            "visionBut the best part comes right at the end In the first scenes showing Precinct 13 we see it is\n",
            "situated in an outskirt of an industrial city factories and office buildings surround it on all\n",
            "sides From this point\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: Some people say this show was good in its early years I disagree with all of em The show is\n",
            "just plain stupid and pathetic My mum hates it I hate it my dad hates it I dont know about my sister\n",
            "but oh well Here some reasons why1 THE CHARACTERS Babies being used as grown up style characters are\n",
            "stupid The babies are just precocious and annoying The grown ups and adults are dumb and unappealing\n",
            "The worst character is that Angelica Pickles she really does it in for your ear drums when you had a\n",
            "long hard and miserable day at the office and also that Kimi Finster who appears later on she is too\n",
            "over optimistic and a pain in the butt She cant decided whither she is French or Japanese it doesnt\n",
            "matter know you are a American Citizen know and thats that Oh what am I talking about all the\n",
            "characters from this show suck2 THE STORIES The stories are unoriginal and dumb The make it like the\n",
            "babies go off on a great adventure yeah to the back yard shed In one episode that little goofy brat\n",
            "Tommy Pickles the Leader broke in to a televisions control room and literally almost destroyed it\n",
            "Dont give kids any idea to smash up normal TV Stations control rooms they pay a awful lot of money\n",
            "for them in real life I can imagine what the broadcasters must of felt like airing this episode they\n",
            "will probably start staring at their machines throughout the day scared that a baby will brake in\n",
            "Sad3 OVER RATED The show has been dragging on for years now and people are still making up stories\n",
            "and new series and spinoffs for this Get off The Simpsons have been going for nearly the same amount\n",
            "of time as this but they are much better and funnier than babies The show is just plain over rated\n",
            "People where is your common senseAnyway I surprised TV Stations across the world want to air this\n",
            "series even off today The show is utter junk and should have never been produced The two movies for\n",
            "this cartoons sucked just the same 210\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: What can I saynot much to this one at all Pretty dull and uninterestingThe actors\n",
            "performances are just OK The only one that shines in any way is Simmons but he only has maybe 3\n",
            "scenes I understand that by keeping his screen time to a minimum he retains the mysterious psychic\n",
            "aura he has but I cant help but feel his talent was wasted No one else rose above mediocreThe story\n",
            "itself seems like it may be intriguing at the beginning but then just doesnt go anywhere There wasnt\n",
            "a single scene in the movie that impressed me or made me feel like I had just seen something special\n",
            "The cinematography was fairly blandI mean desert in a washed out sort of sepianot very inspiringThe\n",
            "story of his childhood pal back outta prison seemed only partially thought out and didnt really add\n",
            "anything to the story other than making an average Twilight Zone script into a full length\n",
            "featureDrab\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: I kept watching it because it seemed like the plot was going somewhere When it ambiguously\n",
            "got there I was very disappointed Im going to tell you what really happened in the next sentence But\n",
            "maybe I wont Maybe Ill just imply something will happen The writers lacked any imagination This is\n",
            "not even a B movie its a made for TV B movie\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: Straight up I love this film I love everything about it It has a great soundtrack it has a\n",
            "lot of recognizable faces and it is funny as hell There are so many plots in this film and every one\n",
            "of them is funny in one way or anotherWhere as Spicolli lit up the screen two years back Drake is\n",
            "almost as memorable of a character All he wants to do is have fun He moves out of the house without\n",
            "his parents consent he skips work whenever he feels like it he is obsessed with sex he loves his\n",
            "drugs and booze and he tries to be a good friend It is his lacksidaisical attitude that makes him\n",
            "such a joy to watch And he comes out with some great lines And there are so many tiny observations\n",
            "that you dont see coming but they make you laugh at the sheer velocity when it hits you One\n",
            "particular moment is when Tommy and Bill are talking about Bills ex girlfriend dating someone else\n",
            "now At the end of the conversation Tommy takes his huge beer bottle and just throws it over his\n",
            "shoulder casually He then says good night and the scene ends It is a perfect scene Tommys world is\n",
            "his own He really lives to party and have fun When the conversation is over his time is over and he\n",
            "doesnt care who he offends in the process He has an innocence about him Its casual is his favourite\n",
            "sayingAnother such classic scene is Reggie handing Bill a donut He says something to him that me and\n",
            "my friends will never forget because we rewound the film ten times and watched that part over and\n",
            "over again and hurt ourselves laughing It has to be seen to be appreciatedWild Life is a throw back\n",
            "to when teen comedies were funny raunchy had a good ear entertained us and just wanted us to get\n",
            "lost in their world for 90 minutes Wild Life does all those things perfectly If this is a film that\n",
            "you havent seen give it a chance It is a classicAlso check out the army store guy that Jim has\n",
            "problems with He is a very familiar face now and it is his first role on the big screen\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: This movie is a real shame not just for the plotthe empty performance of the characters it\n",
            "is for the lack of creativity from the director and all the crew this is maybe one of the worst\n",
            "movies of all timesand it is hard to believe that is the sequel of one of the most famous movies of\n",
            "the 90sI am a great fan of The Mask when I went to see this movie I was expecting to a movie with a\n",
            "good sense of humor a movie with a acceptable plot instead I saw a really bad copy of Chuck Jones\n",
            "and Tex Avery cartoons the movie was not funny even for my 7 years old sister so I wonderWhat was\n",
            "wrong New Line CinemaWas it trying to repeat the success of the first movie or was it trying to\n",
            "create another masterpiece like The Lord of the RingsBecause if they did they were completely out of\n",
            "their minds\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: eXistenZ is simply David Cronenbergs best movie All the people compare it to the Matrix\n",
            "Theyre not even similar If you enjoyed Cronenbergs other works just a little bit youll love this one\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: First time I ever felt I needed to write a reviewI have seen thousands of movies in my life\n",
            "and I like a wide range of movies I am reasonably opened minded and can easily say I enjoyed a movie\n",
            "while still saying yeah it was not good but I enjoyed it I can appreciate the mastery of great\n",
            "movies like The Shaw shank redemption the godfather and American history X I can like good movies in\n",
            "a genre like horror or comedy even if the movie might not be that great I can even enjoy a bad movie\n",
            "that just happens to entertain me Bloodsport I also will try to rate movie fairly even if I did not\n",
            "like it City lights by Charlie Chapin was not a movie I enjoyed but I can appreciate the acting and\n",
            "story lines for the timeI think some people when they go on this site instead of randomly click a\n",
            "rating should take a few ideas into account Try to rate the movie based on how good it actually was\n",
            "Do not let your personal bias affect the rating Also look at other moves you rated and compare the\n",
            "movie you are going to rateThis movie was the worst piece of trash I have ever seen 2 hours of my\n",
            "life where just stolen The acting was awful across the board The scenes where choppy at best However\n",
            "the real disgrace was the story The first 20 minutes we actually had a story that tried to make\n",
            "sense and take the viewer from point A to B However after that it was a nightmare They kept trying\n",
            "to add new elements but nothing was every explained Nothing really ever made sense was steward dead\n",
            "is he alive did he hit by lighting was it really lighting was it aliens is he an alien etc The\n",
            "ending tied nothing together and really did not answer any questions The only positive was nobody\n",
            "cared we where just happy to leave the theater6510 What is wrong with some of you I will admit that\n",
            "the 8 of us where so mad about seeing this we did think what would make it better and we decide to\n",
            "tell a few of our friends that this movie was good so they would have to suffer and see this movie\n",
            "What can I say misery loves company That is really the only reason I can see for a 65 ratingDo not\n",
            "waste your life\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: My main criticism with the movie is the animation I totally agree with everyone else it was\n",
            "very poor Some of the characters seemed to have darker skin tones than they did in the first film\n",
            "which is much better Also the background colours looked rushed and somewhat static It is also a\n",
            "shame that Michael JFox didnt voice Milo he did such a good job and James Arnold Taylor wasnt sure\n",
            "whether he was supposed to sound like Milo or Aladdin I have also taken into consideration the lack\n",
            "of a good storyline the third story was confusing and clumsily told and the second story suffered\n",
            "from poor scripting To make things worse the first one I cant even remember other than a fishing\n",
            "village being haunted or something like that However there was some nice music and good voice\n",
            "talents from John Mahoney Cree Summer Clancy Brown and Tom Wilson that saved the film from total\n",
            "disaster All in all a disappointing sequel to a surprisingly good film 410 Bethany Cox\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: Giant Robot was the most popular Japanese TV serial ever seen on Indian TV It was targeted\n",
            "to children and we saw a robot for the first time in our life Many Indian children must have even\n",
            "seen a machine for the first time outside the school textbooks The serial also showed a child in an\n",
            "adults organization fighting evil No doubt many of us who have seen Giant Robot in our childhood\n",
            "long for our own robots and as a stopgap arrangement look upon our computers in the same way This\n",
            "show also portrayed ideal adults referring at Jerry Johnnys buddy friend and Unicorn chief Azuma We\n",
            "grew to respect Japanese progress and still view Japan as the ideal Asian nationBTW at that time\n",
            "there were no satellite TV channels in India and the govt owned broadcaster did not show much of\n",
            "Disney cartoons I guess that was how child serials like giant Robot got appreciated Nowadays there\n",
            "is Pokemon etc but they are no so fascinating or alluring as Giant robot\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: This might sound weird but I only got to see the first movie The Emperors New Groove\n",
            "yaddayadda a week ago and only because of one episode of the TV show I simply adore Kuzcos character\n",
            "but Kronk isnt that bad either Anyway eventually I decided to watch the second film just so I\n",
            "wouldve seen it Hoped it would be as good as the first one but Im sorry to tell this but the more\n",
            "the humour got American the more I yawned I agreed with Kuzco when he started crying seeing all the\n",
            "cheesy footageStill younger kids and probably veterans too will love this movie to bits if they like\n",
            "the old school moralising Disney that is but I just had expectations that were an eensy teensy\n",
            "little bit hell of a lot higher than they shouldve been Kronk is a lovely character being good\n",
            "hearted and dumb all at once but it were Pacha and Kuzco in drag that woke me up at the end of the\n",
            "movie Ill ignore Rudy for as far thats possibleAnyway great movie just not my style and as they say\n",
            "you always have to be true to your groove\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: The problem I have as a Finn is that most of the actors in this movie are in every Finnish\n",
            "movie I have a feeling that Finland has only like five actors I think that if youre not from Finland\n",
            "you really like this movie as a refreshing noveltyThis movie is about a dreadful chain of events\n",
            "that affects a few people quite harshly Alcoholism cold climate and darkness may all be clichés but\n",
            "theyre still very real in todays Finnish society A lot of people in Finland have depression\n",
            "especially during winterThe tone of the movie is very melancholic I enjoyed it and Louhimes\n",
            "directing was again very solid I liked this movie a lot only negative thing is that you see the same\n",
            "faces that youve seen over and over again\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: Most of the criticism of Attack of Show is from people who are unfairly comparing it to an\n",
            "old computer TV program called The Screen Savers People are upset because G4 decided to cancel the\n",
            "Screen Savers and replace it with the pop culture based Attack of the Show To compare the two shows\n",
            "is like comparing apples to orangesAttack of the Show is a unique hour long program that covers\n",
            "current Generation XY culture It features segments on moviestelevision panel discussions video games\n",
            "new DVD releases sex advice new gadgets MP3 players cell phones etc comic booksgraphic novels\n",
            "magazines and internet fads Its a fun show definitely worth checking out you are in your 20s or 30s\n",
            "I give it an 8 out of 10\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: This is the best comedy period It is so underrated Clever witty humor Great casting Jerry\n",
            "Stiller is the jewel in the show he is so incredibly funny and quirky simply a comical genius Doug\n",
            "and Carrie have great chemistry I so don't see what the hype is about when it comes to Everybody\n",
            "loves Raymond it is SO overrated with lame jokes mostly forced humor and just not the witty show I\n",
            "cant remember laughing in more than 1 episode King of Queens is a rare comedy that has all the right\n",
            "ingredients to give you serious belly laughs which is normally caused by Arthur Spooner I think its\n",
            "about time this comedy gets the hype it deserves and not the lame Raymond & CO\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: Running Out of Time rests somewhere in the middle of Johnny Tos cannon in the solid good\n",
            "category As a crime thriller its not terribly original or overwhelming and the action scenes will\n",
            "not blow you away but it has something else going for it Its a Johnny To film after all it has\n",
            "toAndy Lau has 72 hours to live He decides to play a strange catandmouse game with a hostage\n",
            "negotiator of the HK police played by Lau Ching Wan Thats the plot in a nutshell On top of that To\n",
            "piles layers of twists and turns that keep proceedings interesting throughout It occasionally\n",
            "becomes too convoluted for its own sake but never lets it get the best of it However just as Johnny\n",
            "To is about to hand over a slick and wellmade crime flick which lets face it are dimeadozen he slips\n",
            "in bits and pieces that bring Running Out of Time alive as a full emotional experience providing the\n",
            "soul and heart to the welloiled skeletonThe concepts of synchronism and minimalism staples in his\n",
            "work are explored in great effect here Always subtle letting the images speak for themselves giving\n",
            "them time to develop with long takes and slow tracking shots exemplary cutting to the score its all\n",
            "here A small love story in a bus between Andy Lau and a girl is among the highlights of the film and\n",
            "part of the heart Im talking about So simple yet so powerful Ditto for Laus and Lau Ching Wans car\n",
            "scenes and the bowlingroom showdownHowever something stops me from claiming Running Out of Time is a\n",
            "masterpiece To has all the ability and craftmanship down to a notch but he can also be too\n",
            "workmanlike or bland at times When hes good hes REAL good There are even isolated moment of pure\n",
            "brilliance that are just TOO good for their own sake leaving a bittersweet aftertaste for the rest\n",
            "of the movie Im convinced that if he puts his heart to it he can make a really great film As it is\n",
            "this is another one of his films that is flawed but enjoyable Underneath the slick HK style its the\n",
            "black humour and heartfelt drama that makes this a compelling film Worth watching definitely\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: Will there be please coming an end to hyping movies that are dealing about social conflicts\n",
            "or other human disasters Okay Care is about childabuse Care is about perverts misusing boys in a\n",
            "school and how disgusting it might be if its a movie with a poor script and made with bad playing\n",
            "actors then it stays a bad movie Care is a movie that could have been but is it because it was a\n",
            "tvmovie I dont know but everything seemed so limited that it comes over as some cheap movie that\n",
            "will be seen by some housewifes and fathers who decide not to go to bed There are so many unanswered\n",
            "things in this moviethe relation with his mother for instance or the death of some abused boy from\n",
            "which we know nothing more Care should have been much much better\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n",
            "Review: This movie appears to have been overlooked by everyone Someone should bring it out on VHS\n",
            "and DVD It is an excellent film and far superior to the one with Brooke Shields which was terrible\n",
            "Jean Simmons deserves more credit than she is getting now days It would be nice if all her films\n",
            "were offered on VHS or DVD Jean Simmons was and still is a very good actress She certainly was a\n",
            "beauty In fact she is still a beauty She also has done extremely well on TV She is so much better\n",
            "than many of the actors today\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: When I heard there was to be an ABC Australian Broadcasting Corporation miniseries based on\n",
            "life in Changi WWII POW camp with a focus on elements of comedy I was deeply sceptical and somewhat\n",
            "criticalMy father had served in the second world war Such was the barbarity of the Japanese he was\n",
            "able to talk about the horrors in and around Labuan where he was stationed until only quite recently\n",
            "Along with my father I had been awarded the fortune of knowing many great men of stronger character\n",
            "and spirit than I shall ever have who had witnessed acts of unspeakable barbarity at the hands of\n",
            "the Empire of Japan and had never completely recovered The name Changi is destined to conjure\n",
            "horrific images for ages to comeBut upon viewing I was highly impressed with the cast the characters\n",
            "and the complex plotlines of this wonderful series I now regard Changi as the highlight of my week\n",
            "bear in mind I have viewed only three episodes so far I hope the remaining episodes adhere to the\n",
            "standards set by the first threeThe black humour works uncannily well however the flatulence jokes\n",
            "are a little overdone and while much of the horror has been suppressed the series comes quite close\n",
            "in relaying the undaunted spirit of the survivors who were able to later continue with their lives\n",
            "in spite of the inhibiting memoriesThe flashback format of this series will be difficult for some to\n",
            "followbut I can not think of no better way to do adequate justice to the men who suffered deep\n",
            "emotional scarring proceeding internment when painfully suppressed experiences are remembered\n",
            "sometimes years after the horrorOne of the darkest chapters of the Second World War the 20th century\n",
            "and I would go so far as to say in the history of mankind is being relayed to a new generation\n",
            "through this series and I hope it serves to relay the overwhelming adversity borne by the wartime\n",
            "generationProceeding Changi I dont think I shall ever be able to listen to the poignant tune on the\n",
            "road to Gundagai in the same way again Tune in\n",
            "\n",
            "Actual sentiment: positive\n",
            "Predicted sentiment: positive\n",
            "=====================================================================\n",
            "\n",
            "Review: I was pretty enthusiastic about seeing this movie when it came out Commercials for it made\n",
            "it look quirky and I generally like Morgan Freeman and Chris Rock and the combination of the two\n",
            "seemed like an interesting idea Sadly I was terribly disappointed with Nurse BettyPersonally Ive\n",
            "usually found that graphic violence and comedy dont go all that well together and the only directors\n",
            "that have ever combined the two successfully in my opinion are Tarantino and the Coens There isnt\n",
            "that much violence in Nurse Betty but what violence is in it made me feel kind of weird when I was\n",
            "supposed to laugh Of course for me part of the problem was also that there didnt seem to be many\n",
            "places where I was being asked toThe film doesnt much work as a drama either Renee Zellwegers Betty\n",
            "the storys protagonist is clinically insane and impossible to relate to in any real way I will say\n",
            "Zellweger acts the role quite well and Freeman Rock and Greg Kinnear all do good jobs too The\n",
            "problem is in the writing Freeman is the only person that gets to play an interesting character Its\n",
            "really too bad 310\n",
            "\n",
            "Actual sentiment: negative\n",
            "Predicted sentiment: negative\n",
            "=====================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATfuiHYHq_1"
      },
      "source": [
        "Now predict on all the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvWQGLXhzHtn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6aaf51cb9ad44c94b6a174a8768904f7",
            "51d23e1199274477a69557c74609afb2",
            "029f74818c6842d7a28af62032418880",
            "8db144e9144141779a1088c4bc000a99",
            "210517aede4f4cfab9120fdeb3d8361a",
            "df9bc2dc2b3c4fee98affdd7f5ca1ef6",
            "b684a47485af4cb1934d57cbb03a4f57",
            "942d20b134964d1d895af69938918464"
          ]
        },
        "outputId": "c0f5490b-2ade-4795-fa3d-1f0f1746e23c"
      },
      "source": [
        "loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aaf51cb9ad44c94b6a174a8768904f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBxEcXeWGafd"
      },
      "source": [
        "Let's check if the model generates any invalid text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_qylwYGXgwY"
      },
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in ['positive', 'negative']:\n",
        "    print(i, 'detected invalid prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpU_VkFGIgnw"
      },
      "source": [
        "This great is great! Our model hasn't generated any invalid prediction. Let's calculate accuarcy and other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdJcQODoOChP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22fc6852-5443-43e4-d87e-5a5266ddffd9"
      },
      "source": [
        "metrics.accuracy_score(targets, outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.94712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YepnSgI5OKti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "a2914edf-d572-4166-a886-6c0d731835e5"
      },
      "source": [
        "print(metrics.classification_report(targets, outputs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.95      0.95      0.95     12500\n",
            "    positive       0.95      0.95      0.95     12500\n",
            "\n",
            "    accuracy                           0.95     25000\n",
            "   macro avg       0.95      0.95      0.95     25000\n",
            "weighted avg       0.95      0.95      0.95     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcZqrJELrRVw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhqigmiw2hVh"
      },
      "source": [
        "## Emotion classification\n",
        "\n",
        "While most of the sentiment-analysis datasets are binary with 'postive' and 'negative' sentiments, [Elvis Saravia](https://twitter.com/omarsar0)  has put together a great [dataset](https://github.com/dair-ai/emotion_dataset) for emotion recognition. The task is given some text classifiy the text into one of the following six emotions \n",
        "\n",
        "'sadness', 'joy', 'anger', 'fear', 'surprise', 'love'.\n",
        "\n",
        "Here's the [original notebook](https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X#scrollTo=pSzoz9InH0Ta) which trains ROBERTa model to classify the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B4IhzEgO21B"
      },
      "source": [
        "### Download and view data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eQhtsD65svj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21704aeb-7940-4d5a-c6ff-32424b321c6c"
      },
      "source": [
        "#!wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
        "!wget https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
        "#!wget https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 07:55:45--  https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/1pzkadrvffbqw6o/train.txt [following]\n",
            "--2020-12-21 07:55:45--  https://www.dropbox.com/s/raw/1pzkadrvffbqw6o/train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com/cd/0/inline/BFdQANi1T7_uTEQz0vIY1_uzFQw-wfTTAfWohMututfMWGQNPvEDy9kg9YQPSsoM3g7YKKl7D3n8O0qM9cxbrY0-ryJ414xXKEa8xoI7m7psLpTro5LqfQbJi-QHf_YHKtA/file# [following]\n",
            "--2020-12-21 07:55:46--  https://uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com/cd/0/inline/BFdQANi1T7_uTEQz0vIY1_uzFQw-wfTTAfWohMututfMWGQNPvEDy9kg9YQPSsoM3g7YKKl7D3n8O0qM9cxbrY0-ryJ414xXKEa8xoI7m7psLpTro5LqfQbJi-QHf_YHKtA/file\n",
            "Resolving uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com (uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:601f:15::a27d:90f\n",
            "Connecting to uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com (uc293c91fe2ec90a3d4d34ebe1a0.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1658616 (1.6M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>]   1.58M  4.11MB/s    in 0.4s    \n",
            "\n",
            "2020-12-21 07:55:47 (4.11 MB/s) - ‘train.txt’ saved [1658616/1658616]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVrcVbvx74G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8336b670-47cc-4d69-b07c-a43fee0f50bf"
      },
      "source": [
        "!mkdir emotion_data\n",
        "!mv *.txt emotion_data"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘emotion_data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOpnh3Y06BGU"
      },
      "source": [
        "train_path = \"emotion_data/train.txt\"\n",
        "test_path = \"emotion_data/test.txt\"\n",
        "val_path = \"emotion_data/val.txt\"\n",
        "\n",
        "## emotion labels\n",
        "label2int = {\n",
        "  \"irritated\": 0,\n",
        "  \"disappointed\": 1,\n",
        "  \"neutral\": 2,\n",
        "  \"happy\": 3,\n",
        "  \"delighted\": 4\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4sDek6T8PXE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "6233b2c6-d4f9-46db-a7cf-c93b68c5eaa2"
      },
      "source": [
        "data = pd.read_csv(train_path, sep=\";\", header=None, names=['text', 'emotion'],\n",
        "                               engine=\"c\")\n",
        "data.emotion.value_counts().plot.bar()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c12954668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaKp3E1T8kkm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4017492f-3546-43da-9999-296f376b6686"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral didnt feel humiliated</td>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>delighted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text       emotion\n",
              "0                      neutral didnt feel humiliated  disappointed\n",
              "1  i can go from feeling so hopeless to so damned...  disappointed\n",
              "2   im grabbing a minute to post i feel greedy wrong  disappointed\n",
              "3  i am ever feeling nostalgic about the fireplac...     delighted\n",
              "4                               i am feeling grouchy  disappointed"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Gt1WyPBL-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b19f6a-9fb0-4612-9dfc-73d4cb1ecf7c"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text       9603\n",
              "emotion    9602\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KybpXVl1Die5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a520e79a-4c6d-4493-add2-24fbaa65fe19"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cANrUEXhO8QY"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GsMQdqMPCN7"
      },
      "source": [
        "Here also we will process the examples in the same way we did above. If the label is 'love' we will ask the model to predict the text 'love'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKh6m92eKZc4"
      },
      "source": [
        "Lets check how t5 encodes the following labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDnMp5-fDIAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96082726-887c-4897-be6e-dc6d841e733d"
      },
      "source": [
        "emotions = [ \"irritated\", \"disappointed\", \"neutral\", \"happy\", \"delighted\"]\n",
        "for em in emotions:\n",
        "  print(len(tokenizer.encode(em)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8VIZIWFOwMj"
      },
      "source": [
        "Here also all the labels are encoded as single ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i8QD-3MDrWq"
      },
      "source": [
        "class EmotionDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
        "    self.path = os.path.join(data_dir, type_path + '.txt')\n",
        "\n",
        "    self.data_column = \"text\"\n",
        "    self.class_column = \"emotion\"\n",
        "    self.data = pd.read_csv(self.path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
        "                            engine=\"python\")\n",
        "    \n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self._build()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "  \n",
        "  def _build(self):\n",
        "    for idx in range(len(self.data)):\n",
        "      input_, target = self.data.loc[idx, self.data_column], self.data.loc[idx, self.class_column]      \n",
        "      \n",
        "      input_ = input_ + ' </s>'\n",
        "      target = target + \" </s>\"\n",
        "\n",
        "       # tokenize inputs\n",
        "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "          [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "       # tokenize targets\n",
        "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "          [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "      self.inputs.append(tokenized_inputs)\n",
        "      self.targets.append(tokenized_targets)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRz5jyl3FBkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0d6077-fd38-4c9c-cafa-c3336a1fb025"
      },
      "source": [
        "dataset = EmotionDataset(tokenizer, 'emotion_data', 'val', 512)\n",
        "len(dataset)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxT6QzUAFQN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6973aa-005b-4595-8f46-4fe695aabb57"
      },
      "source": [
        "data = dataset[42]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i had previously tried to get the broken distance comb through a store, and they wanted to help, but because of illness and only borrowed staff, i could not get answers to what happened in the case for a very long time. when i finally contacted you directly, i was just so happy that we finally managed to get a new distance cam.\n",
            "delighted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBVHtdIuFpID"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEWi6c-pGZV9"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGrpDJnLPQ0Q"
      },
      "source": [
        "As I said above there's no need to change the model or add task specific head or any other hyperparameters, we'll just change the dataset and that's it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDep-uIcGYX2"
      },
      "source": [
        "!mkdir -p t5_emotion"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgNOy7a4LJ9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e40a6f8-fb22-46a3-8d07-f1fb30fd765b"
      },
      "source": [
        "args_dict.update({'data_dir': 'emotion_data', 'output_dir': 't5_emotion', 'num_train_epochs':2})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data_dir': 'emotion_data', 'output_dir': 't5_emotion', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_seq_length': 512, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 8, 'eval_batch_size': 8, 'num_train_epochs': 2, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at783kr7KvS4"
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LBvpP01KvTA"
      },
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return EmotionDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Tty_OHGlvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d86605-5ce5-47ad-e3eb-6b2a939f3f58"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:transformers.configuration_utils:Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
            "INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIsW9pwEG27D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0301ca87-5f6c-40c7-e952-1403294f4456"
      },
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:GPU available: True, used: True\n",
            "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmk4GsEMHTfZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4c913726332c4bff99e5307b817b4e72",
            "e50a976c7a6345999923a56a97bef614",
            "fd86a1eadb4f403381b6d7d5588766b5",
            "57ac8ec882964d0dbf9289400ffaa1a0",
            "20231777aa164a9d8dac3d5a4cc55b63",
            "dcbc6408637240f8b580ab2cf3c24dbb",
            "e2684d80a827418db858dca73dd30c52",
            "06d4184cb4c14f479712a64dd987ea19",
            "fcdd867494b641afb4975d99c2bdeac8",
            "a69f5b095c7f479e8d17e127676c8396",
            "75b6c7b980ca4c809d2e6d7879fca204",
            "ec3768be32944b35b68bba180b4d0976",
            "83411701a55a45a196989b6f1cb3717b",
            "c84be8af5614404bb615d387bba90556",
            "cea81db3622e4a3f884187664e271309",
            "4b15b28efba142488f3ace40c672fded",
            "4b8815f08bb64ae784aef7c4f0b41a73",
            "daf020ca7c564da1abaa066331a3ef96",
            "8aebd9fbba2d4aaa938b50d9f3beb025",
            "a5c67e852c3a42a2a249b298245f93dc",
            "ce997619a8f14db684b84571e2d61380",
            "17bff8c40191450cb9ac056f732c3f60",
            "bd61fd8370a1451287a28f4b0060bb5a",
            "bf7a19930c434276bb322c8b40d57e27",
            "336657cff8ad4cf5b0981b5d24e55085",
            "833981e781804953a8b3cddfb3249cb6",
            "c65ef68e147f405e97f0f5df29211f6b",
            "d68af589009848089403dfc5fc2cc73a",
            "51c575b1e58e41fdb9c202d128684b5c",
            "13f48421b53d4b20b26fc0a58d5ea52f",
            "e820cac698fa4152b9d7cfdb01ad0dd8",
            "1ffbb7a6007041f487df2b87136472b9"
          ]
        },
        "outputId": "05e4ce16-97f2-47fc-9c96-9d69f8138b00"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "    | Name                                                                  | Type                       | Params\n",
            "-----------------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                                 | T5ForConditionalGeneration | 222 M \n",
            "1   | model.shared                                                          | Embedding                  | 24 M  \n",
            "2   | model.encoder                                                         | T5Stack                    | 109 M \n",
            "3   | model.encoder.block                                                   | ModuleList                 | 84 M  \n",
            "4   | model.encoder.block.0                                                 | T5Block                    | 7 M   \n",
            "5   | model.encoder.block.0.layer                                           | ModuleList                 | 7 M   \n",
            "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "22  | model.encoder.block.1                                                 | T5Block                    | 7 M   \n",
            "23  | model.encoder.block.1.layer                                           | ModuleList                 | 7 M   \n",
            "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "39  | model.encoder.block.2                                                 | T5Block                    | 7 M   \n",
            "40  | model.encoder.block.2.layer                                           | ModuleList                 | 7 M   \n",
            "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "56  | model.encoder.block.3                                                 | T5Block                    | 7 M   \n",
            "57  | model.encoder.block.3.layer                                           | ModuleList                 | 7 M   \n",
            "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "73  | model.encoder.block.4                                                 | T5Block                    | 7 M   \n",
            "74  | model.encoder.block.4.layer                                           | ModuleList                 | 7 M   \n",
            "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "90  | model.encoder.block.5                                                 | T5Block                    | 7 M   \n",
            "91  | model.encoder.block.5.layer                                           | ModuleList                 | 7 M   \n",
            "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "107 | model.encoder.block.6                                                 | T5Block                    | 7 M   \n",
            "108 | model.encoder.block.6.layer                                           | ModuleList                 | 7 M   \n",
            "109 | model.encoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "110 | model.encoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "111 | model.encoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "112 | model.encoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "113 | model.encoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "114 | model.encoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "115 | model.encoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "116 | model.encoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "117 | model.encoder.block.6.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "118 | model.encoder.block.6.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "119 | model.encoder.block.6.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "120 | model.encoder.block.6.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "122 | model.encoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "123 | model.encoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "124 | model.encoder.block.7                                                 | T5Block                    | 7 M   \n",
            "125 | model.encoder.block.7.layer                                           | ModuleList                 | 7 M   \n",
            "126 | model.encoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "127 | model.encoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "128 | model.encoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "129 | model.encoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "130 | model.encoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "131 | model.encoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "132 | model.encoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "133 | model.encoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "134 | model.encoder.block.7.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "135 | model.encoder.block.7.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "136 | model.encoder.block.7.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "137 | model.encoder.block.7.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "139 | model.encoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "140 | model.encoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "141 | model.encoder.block.8                                                 | T5Block                    | 7 M   \n",
            "142 | model.encoder.block.8.layer                                           | ModuleList                 | 7 M   \n",
            "143 | model.encoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "144 | model.encoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "145 | model.encoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "146 | model.encoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "147 | model.encoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "148 | model.encoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "149 | model.encoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "150 | model.encoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "151 | model.encoder.block.8.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "152 | model.encoder.block.8.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "153 | model.encoder.block.8.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "154 | model.encoder.block.8.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "156 | model.encoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "157 | model.encoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "158 | model.encoder.block.9                                                 | T5Block                    | 7 M   \n",
            "159 | model.encoder.block.9.layer                                           | ModuleList                 | 7 M   \n",
            "160 | model.encoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "161 | model.encoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "162 | model.encoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "163 | model.encoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "164 | model.encoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "165 | model.encoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "166 | model.encoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "167 | model.encoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "168 | model.encoder.block.9.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "169 | model.encoder.block.9.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "170 | model.encoder.block.9.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "171 | model.encoder.block.9.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "173 | model.encoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "174 | model.encoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "175 | model.encoder.block.10                                                | T5Block                    | 7 M   \n",
            "176 | model.encoder.block.10.layer                                          | ModuleList                 | 7 M   \n",
            "177 | model.encoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "178 | model.encoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "179 | model.encoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "180 | model.encoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "181 | model.encoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "182 | model.encoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "183 | model.encoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "184 | model.encoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "185 | model.encoder.block.10.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "186 | model.encoder.block.10.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "187 | model.encoder.block.10.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "188 | model.encoder.block.10.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "189 | model.encoder.block.10.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "190 | model.encoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "191 | model.encoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "192 | model.encoder.block.11                                                | T5Block                    | 7 M   \n",
            "193 | model.encoder.block.11.layer                                          | ModuleList                 | 7 M   \n",
            "194 | model.encoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "195 | model.encoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "196 | model.encoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "197 | model.encoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "198 | model.encoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "199 | model.encoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "200 | model.encoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "201 | model.encoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "202 | model.encoder.block.11.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "203 | model.encoder.block.11.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "204 | model.encoder.block.11.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "205 | model.encoder.block.11.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "206 | model.encoder.block.11.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "207 | model.encoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "208 | model.encoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "209 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "210 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
            "211 | model.decoder                                                         | T5Stack                    | 137 M \n",
            "212 | model.decoder.block                                                   | ModuleList                 | 113 M \n",
            "213 | model.decoder.block.0                                                 | T5Block                    | 9 M   \n",
            "214 | model.decoder.block.0.layer                                           | ModuleList                 | 9 M   \n",
            "215 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "216 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "217 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "218 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "219 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "220 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "222 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "223 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "224 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "225 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "226 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "227 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "228 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "229 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "230 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 384   \n",
            "231 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "232 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "233 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "234 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "235 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "236 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "237 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "238 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "239 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
            "240 | model.decoder.block.1                                                 | T5Block                    | 9 M   \n",
            "241 | model.decoder.block.1.layer                                           | ModuleList                 | 9 M   \n",
            "242 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "243 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "244 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "245 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "246 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "247 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "248 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "249 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "250 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "251 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "252 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "253 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "254 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "255 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "256 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "257 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "258 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "259 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "260 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "261 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "262 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "263 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "264 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
            "265 | model.decoder.block.2                                                 | T5Block                    | 9 M   \n",
            "266 | model.decoder.block.2.layer                                           | ModuleList                 | 9 M   \n",
            "267 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "268 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "269 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "270 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "271 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "272 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "273 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "274 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "275 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "276 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "277 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "278 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "279 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "280 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "281 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "282 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "283 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "284 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "285 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "286 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "287 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "288 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "289 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
            "290 | model.decoder.block.3                                                 | T5Block                    | 9 M   \n",
            "291 | model.decoder.block.3.layer                                           | ModuleList                 | 9 M   \n",
            "292 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "293 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "294 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "295 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "296 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "297 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "298 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "299 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "300 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "301 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "302 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "303 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "304 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "305 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "306 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "307 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "308 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "309 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "310 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "311 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "312 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "313 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "314 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
            "315 | model.decoder.block.4                                                 | T5Block                    | 9 M   \n",
            "316 | model.decoder.block.4.layer                                           | ModuleList                 | 9 M   \n",
            "317 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "318 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "319 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "320 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "321 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "322 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "323 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "324 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "325 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "326 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "327 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "328 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "329 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "330 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "331 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "332 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "333 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "334 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "335 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "336 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "337 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "338 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "339 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
            "340 | model.decoder.block.5                                                 | T5Block                    | 9 M   \n",
            "341 | model.decoder.block.5.layer                                           | ModuleList                 | 9 M   \n",
            "342 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "343 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "344 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "345 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "346 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "347 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "348 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "349 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "350 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "351 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "352 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "353 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "354 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "355 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "356 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "357 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "358 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "359 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "360 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "361 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "362 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "363 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "364 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
            "365 | model.decoder.block.6                                                 | T5Block                    | 9 M   \n",
            "366 | model.decoder.block.6.layer                                           | ModuleList                 | 9 M   \n",
            "367 | model.decoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "368 | model.decoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "369 | model.decoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "370 | model.decoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "371 | model.decoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "372 | model.decoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "373 | model.decoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "374 | model.decoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "375 | model.decoder.block.6.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "376 | model.decoder.block.6.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "377 | model.decoder.block.6.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "378 | model.decoder.block.6.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "379 | model.decoder.block.6.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "380 | model.decoder.block.6.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "381 | model.decoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "382 | model.decoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "383 | model.decoder.block.6.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "384 | model.decoder.block.6.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "385 | model.decoder.block.6.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "386 | model.decoder.block.6.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "387 | model.decoder.block.6.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "388 | model.decoder.block.6.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "389 | model.decoder.block.6.layer.2.dropout                                 | Dropout                    | 0     \n",
            "390 | model.decoder.block.7                                                 | T5Block                    | 9 M   \n",
            "391 | model.decoder.block.7.layer                                           | ModuleList                 | 9 M   \n",
            "392 | model.decoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "393 | model.decoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "394 | model.decoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "395 | model.decoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "396 | model.decoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "397 | model.decoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "398 | model.decoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "399 | model.decoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "400 | model.decoder.block.7.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "401 | model.decoder.block.7.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "402 | model.decoder.block.7.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "403 | model.decoder.block.7.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "404 | model.decoder.block.7.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "405 | model.decoder.block.7.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "406 | model.decoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "407 | model.decoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "408 | model.decoder.block.7.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "409 | model.decoder.block.7.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "410 | model.decoder.block.7.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "411 | model.decoder.block.7.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "412 | model.decoder.block.7.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "413 | model.decoder.block.7.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "414 | model.decoder.block.7.layer.2.dropout                                 | Dropout                    | 0     \n",
            "415 | model.decoder.block.8                                                 | T5Block                    | 9 M   \n",
            "416 | model.decoder.block.8.layer                                           | ModuleList                 | 9 M   \n",
            "417 | model.decoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "418 | model.decoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "419 | model.decoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "420 | model.decoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "421 | model.decoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "422 | model.decoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "423 | model.decoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "424 | model.decoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "425 | model.decoder.block.8.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "426 | model.decoder.block.8.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "427 | model.decoder.block.8.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "428 | model.decoder.block.8.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "429 | model.decoder.block.8.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "430 | model.decoder.block.8.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "431 | model.decoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "432 | model.decoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "433 | model.decoder.block.8.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "434 | model.decoder.block.8.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "435 | model.decoder.block.8.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "436 | model.decoder.block.8.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "437 | model.decoder.block.8.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "438 | model.decoder.block.8.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "439 | model.decoder.block.8.layer.2.dropout                                 | Dropout                    | 0     \n",
            "440 | model.decoder.block.9                                                 | T5Block                    | 9 M   \n",
            "441 | model.decoder.block.9.layer                                           | ModuleList                 | 9 M   \n",
            "442 | model.decoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "443 | model.decoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "444 | model.decoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "445 | model.decoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "446 | model.decoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "447 | model.decoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "448 | model.decoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "449 | model.decoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "450 | model.decoder.block.9.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "451 | model.decoder.block.9.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "452 | model.decoder.block.9.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "453 | model.decoder.block.9.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "454 | model.decoder.block.9.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "455 | model.decoder.block.9.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "456 | model.decoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "457 | model.decoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "458 | model.decoder.block.9.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "459 | model.decoder.block.9.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "460 | model.decoder.block.9.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "461 | model.decoder.block.9.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "462 | model.decoder.block.9.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "463 | model.decoder.block.9.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "464 | model.decoder.block.9.layer.2.dropout                                 | Dropout                    | 0     \n",
            "465 | model.decoder.block.10                                                | T5Block                    | 9 M   \n",
            "466 | model.decoder.block.10.layer                                          | ModuleList                 | 9 M   \n",
            "467 | model.decoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "468 | model.decoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "469 | model.decoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "470 | model.decoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "471 | model.decoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "472 | model.decoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "473 | model.decoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "474 | model.decoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "475 | model.decoder.block.10.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "476 | model.decoder.block.10.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "477 | model.decoder.block.10.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "478 | model.decoder.block.10.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "479 | model.decoder.block.10.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "480 | model.decoder.block.10.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "481 | model.decoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "482 | model.decoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "483 | model.decoder.block.10.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "484 | model.decoder.block.10.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "485 | model.decoder.block.10.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "486 | model.decoder.block.10.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "487 | model.decoder.block.10.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "488 | model.decoder.block.10.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "489 | model.decoder.block.10.layer.2.dropout                                | Dropout                    | 0     \n",
            "490 | model.decoder.block.11                                                | T5Block                    | 9 M   \n",
            "491 | model.decoder.block.11.layer                                          | ModuleList                 | 9 M   \n",
            "492 | model.decoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "493 | model.decoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "494 | model.decoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "495 | model.decoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "496 | model.decoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "497 | model.decoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "498 | model.decoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "499 | model.decoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "500 | model.decoder.block.11.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "501 | model.decoder.block.11.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "502 | model.decoder.block.11.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "503 | model.decoder.block.11.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "504 | model.decoder.block.11.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "505 | model.decoder.block.11.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "506 | model.decoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "507 | model.decoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "508 | model.decoder.block.11.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "509 | model.decoder.block.11.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "510 | model.decoder.block.11.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "511 | model.decoder.block.11.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "512 | model.decoder.block.11.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "513 | model.decoder.block.11.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "514 | model.decoder.block.11.layer.2.dropout                                | Dropout                    | 0     \n",
            "515 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "516 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
            "517 | model.lm_head                                                         | Linear                     | 24 M  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c913726332c4bff99e5307b817b4e72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcdd867494b641afb4975d99c2bdeac8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b8815f08bb64ae784aef7c4f0b41a73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_val_loss = tensor(0.8511, device='cuda:0')\n",
            "\n",
            "INFO:__main__:loss = tensor(0.2126, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.2126, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.8511, device='cuda:0')\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "336657cff8ad4cf5b0981b5d24e55085",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_train_loss = tensor(0.6341, device='cuda:0')\n",
            "\n",
            "INFO:__main__:avg_val_loss = tensor(0.8803, device='cuda:0')\n",
            "\n",
            "INFO:__main__:epoch = 0\n",
            "\n",
            "INFO:__main__:loss = tensor(0.0775, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.0775, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.8803, device='cuda:0')\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdWdHG0RP5J"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq7cCiOPRQzs"
      },
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKsHzqGMRQzz"
      },
      "source": [
        "dataset = EmotionDataset(tokenizer, 'emotion_data', 'test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7s7IpERQz5"
      },
      "source": [
        "it = iter(loader)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_79Jk36RQz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9702233a-1ccd-4f4f-9df9-dc24490a8667"
      },
      "source": [
        "batch = next(it)\n",
        "batch[\"source_ids\"].shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQZKyEaVRQ0B"
      },
      "source": [
        "outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "dec = [tokenizer.decode(ids) for ids in outs]\n",
        "\n",
        "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
        "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjhiBcrRQ0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2016408b-bf45-49ff-c334-9c10444d24c0"
      },
      "source": [
        "for i in range(32):\n",
        "    c = texts[i]\n",
        "    lines = textwrap.wrap(\"text:\\n%s\\n\" % c, width=100)\n",
        "    print(\"\\n\".join(lines))\n",
        "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
        "    print(\"predicted sentiment: %s\" % dec[i])\n",
        "    print(\"=====================================================================\\n\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: with a guarantee expired less than a week, the consumer could meet\n",
            "\n",
            "Actual sentiment: neutral\n",
            "predicted sentiment: disappointed\n",
            "=====================================================================\n",
            "\n",
            "text: my problem is solved quickly and easily.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: fast chat contact, exact information received\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: nothing\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: \n",
            "=====================================================================\n",
            "\n",
            "text: the desired spare parts in austria or at least in vienna make orderable and collectable!\n",
            "ordering spare parts abroad, where after 2 days and 2 phone calls my written request is still\n",
            "answered, is extremely customer-unfriendly! in addition, my philips device is not usable, which is\n",
            "more than unpleasant...\n",
            "\n",
            "Actual sentiment: disappointed\n",
            "predicted sentiment: disappointed\n",
            "=====================================================================\n",
            "\n",
            "text: it was fine.\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: the lady on the phone was very nice and very competent and has solved my concerns quickly.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: very nice and could help me immediately\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: very nice and competent woman. no eternal waiting in the waiting loop. keep it up\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: because my needs have been fully accepted and supported, also the kindness and timeliness of\n",
            "the people i spoke with demonstrate that it is a company that you can always trust.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: because contrary to the homepage information he could give the correct information (where the\n",
            "product number is) (on the homepage it is insufficient). and nice.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: the lady on the phone was very friendly\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: emails were processed only after sending them three times\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: disappointed\n",
            "=====================================================================\n",
            "\n",
            "text: all problems solved\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: \n",
            "=====================================================================\n",
            "\n",
            "text: it is by no means the employee! i think it's just totally disappointing that you buy extra\n",
            "quality equipment and that after the warranty, you simply lost if the device has a defect. i really\n",
            "don't find that satisfying!!\n",
            "\n",
            "Actual sentiment: neutral\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: i was offered no solution to my problem.\n",
            "\n",
            "Actual sentiment: disappointed\n",
            "predicted sentiment: disappointed\n",
            "=====================================================================\n",
            "\n",
            "text: i was fully satisfied with the support i had.\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: got good help and everything was solved smoothly\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: i have not received any notification from philips or klarna, as i have been informed,\n",
            "regarding my order and invoice. this is not satisfactory.\n",
            "\n",
            "Actual sentiment: disappointed\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: my request was dealt with quickly and easily\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: the information on your web site indicating what a serial number looked like and where it was\n",
            "located were inadequate. the location photo showed the interior of the shaving head area whereas the\n",
            "number was actually on the rear of the shaver. second, there was an indication that the serial\n",
            "number was 8 or more digits long whereas it was actually 5.\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: disappointed\n",
            "=====================================================================\n",
            "\n",
            "text: i did not understand your payment system klarna at first\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: easy to understand instructions\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: pleasant contact person on the phone, helpful, further procedure was discussed to help me as a\n",
            "customer, very good.\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: fast and efficient, was supported to fix an issue without feeling i had to jump through hoops\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: nice communication, helpful solutions\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: all in all, top!!!\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: very friendly, competent answer also with offer for 10% reduction of my product question.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: excellent products and excellent service\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: service was ok\n",
            "\n",
            "Actual sentiment: happy\n",
            "predicted sentiment: happy\n",
            "=====================================================================\n",
            "\n",
            "text: the advisor was very pleasant and my issue was dealt with efficiently and my replacement\n",
            "charger is working perfectly.\n",
            "\n",
            "Actual sentiment: delighted\n",
            "predicted sentiment: delighted\n",
            "=====================================================================\n",
            "\n",
            "text: i didn't get the answer on time, i had to ask behind and only when i threatened to buy a cheap\n",
            "copy of the toothbrush i heard about you.\n",
            "\n",
            "Actual sentiment: disappointed\n",
            "predicted sentiment: \n",
            "=====================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq8M8nbTSJlE"
      },
      "source": [
        "#### Test Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-oIXmoCR6kl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "53dba40d2405456e8c2dfb64bc4a6e81",
            "68b5668ca62f4499aa28e2159ae724a5",
            "240fb77561064fa9bd3f3b4a5932feb1",
            "b48e067c2b25477b98a749b73019acdc",
            "e6319343ad9a442d91b044d88effd98a",
            "d9b23d64e3a34e9bb1c4d8030027da99",
            "7702692d80cf45f9a3684935775d2a0f",
            "83308db5dd4b418498116f5539a81216"
          ]
        },
        "outputId": "432fb2ac-428f-46e7-a0d0-adaed4c2aa5a"
      },
      "source": [
        "dataset = EmotionDataset(tokenizer, 'emotion_data', 'test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53dba40d2405456e8c2dfb64bc4a6e81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9CYCGM6SRzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f51614a-ec68-4603-be66-13912f414e5f"
      },
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in emotions:\n",
        "    print(i, 'detected invalid prediction')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 detected invalid prediction\n",
            "51 detected invalid prediction\n",
            "54 detected invalid prediction\n",
            "65 detected invalid prediction\n",
            "83 detected invalid prediction\n",
            "87 detected invalid prediction\n",
            "96 detected invalid prediction\n",
            "108 detected invalid prediction\n",
            "110 detected invalid prediction\n",
            "119 detected invalid prediction\n",
            "129 detected invalid prediction\n",
            "130 detected invalid prediction\n",
            "162 detected invalid prediction\n",
            "179 detected invalid prediction\n",
            "213 detected invalid prediction\n",
            "222 detected invalid prediction\n",
            "249 detected invalid prediction\n",
            "264 detected invalid prediction\n",
            "281 detected invalid prediction\n",
            "286 detected invalid prediction\n",
            "296 detected invalid prediction\n",
            "299 detected invalid prediction\n",
            "301 detected invalid prediction\n",
            "344 detected invalid prediction\n",
            "346 detected invalid prediction\n",
            "365 detected invalid prediction\n",
            "377 detected invalid prediction\n",
            "386 detected invalid prediction\n",
            "398 detected invalid prediction\n",
            "400 detected invalid prediction\n",
            "428 detected invalid prediction\n",
            "438 detected invalid prediction\n",
            "442 detected invalid prediction\n",
            "449 detected invalid prediction\n",
            "453 detected invalid prediction\n",
            "454 detected invalid prediction\n",
            "459 detected invalid prediction\n",
            "462 detected invalid prediction\n",
            "467 detected invalid prediction\n",
            "475 detected invalid prediction\n",
            "481 detected invalid prediction\n",
            "488 detected invalid prediction\n",
            "493 detected invalid prediction\n",
            "505 detected invalid prediction\n",
            "514 detected invalid prediction\n",
            "517 detected invalid prediction\n",
            "518 detected invalid prediction\n",
            "521 detected invalid prediction\n",
            "522 detected invalid prediction\n",
            "532 detected invalid prediction\n",
            "535 detected invalid prediction\n",
            "538 detected invalid prediction\n",
            "551 detected invalid prediction\n",
            "554 detected invalid prediction\n",
            "561 detected invalid prediction\n",
            "564 detected invalid prediction\n",
            "569 detected invalid prediction\n",
            "581 detected invalid prediction\n",
            "597 detected invalid prediction\n",
            "603 detected invalid prediction\n",
            "605 detected invalid prediction\n",
            "606 detected invalid prediction\n",
            "607 detected invalid prediction\n",
            "610 detected invalid prediction\n",
            "613 detected invalid prediction\n",
            "620 detected invalid prediction\n",
            "628 detected invalid prediction\n",
            "629 detected invalid prediction\n",
            "631 detected invalid prediction\n",
            "635 detected invalid prediction\n",
            "639 detected invalid prediction\n",
            "642 detected invalid prediction\n",
            "661 detected invalid prediction\n",
            "671 detected invalid prediction\n",
            "672 detected invalid prediction\n",
            "674 detected invalid prediction\n",
            "679 detected invalid prediction\n",
            "687 detected invalid prediction\n",
            "689 detected invalid prediction\n",
            "696 detected invalid prediction\n",
            "697 detected invalid prediction\n",
            "698 detected invalid prediction\n",
            "699 detected invalid prediction\n",
            "727 detected invalid prediction\n",
            "728 detected invalid prediction\n",
            "733 detected invalid prediction\n",
            "746 detected invalid prediction\n",
            "749 detected invalid prediction\n",
            "752 detected invalid prediction\n",
            "753 detected invalid prediction\n",
            "754 detected invalid prediction\n",
            "765 detected invalid prediction\n",
            "767 detected invalid prediction\n",
            "769 detected invalid prediction\n",
            "772 detected invalid prediction\n",
            "773 detected invalid prediction\n",
            "777 detected invalid prediction\n",
            "779 detected invalid prediction\n",
            "796 detected invalid prediction\n",
            "798 detected invalid prediction\n",
            "808 detected invalid prediction\n",
            "810 detected invalid prediction\n",
            "818 detected invalid prediction\n",
            "823 detected invalid prediction\n",
            "834 detected invalid prediction\n",
            "836 detected invalid prediction\n",
            "837 detected invalid prediction\n",
            "849 detected invalid prediction\n",
            "861 detected invalid prediction\n",
            "865 detected invalid prediction\n",
            "867 detected invalid prediction\n",
            "869 detected invalid prediction\n",
            "880 detected invalid prediction\n",
            "903 detected invalid prediction\n",
            "905 detected invalid prediction\n",
            "907 detected invalid prediction\n",
            "918 detected invalid prediction\n",
            "926 detected invalid prediction\n",
            "932 detected invalid prediction\n",
            "936 detected invalid prediction\n",
            "944 detected invalid prediction\n",
            "950 detected invalid prediction\n",
            "963 detected invalid prediction\n",
            "964 detected invalid prediction\n",
            "968 detected invalid prediction\n",
            "970 detected invalid prediction\n",
            "975 detected invalid prediction\n",
            "978 detected invalid prediction\n",
            "981 detected invalid prediction\n",
            "984 detected invalid prediction\n",
            "998 detected invalid prediction\n",
            "1001 detected invalid prediction\n",
            "1003 detected invalid prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE0WX_GbSRzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b66037-ea89-4535-86e1-bc9be1c26ef8"
      },
      "source": [
        "metrics.accuracy_score(targets, outputs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWkOZ7BASRz5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "3955083b-1d3b-446d-c03e-0ec2fd9b0369"
      },
      "source": [
        "print(metrics.classification_report(targets, outputs))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b57a947d6f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     \"\"\"\n\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32, 1004]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6p9MGb6lWL5"
      },
      "source": [
        "Now lets plot  the confusion matrix and see for which classes our model is getting confused"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RtgfuzucFeN"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ioVvq5rcHZE"
      },
      "source": [
        "cm = metrics.confusion_matrix(targets, outputs)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rM5XS09SSdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e79e1865-5e67-4478-8a8f-751b4da2b18f"
      },
      "source": [
        "df_cm = pd.DataFrame(cm, index = [\"irritated\", \"disappointed\", \"neutral\", \"happy\", \"delighted\"], columns = [\"irritated\", \"disappointed\", \"neutral\", \"happy\", \"delighted\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True, cmap='Purples', fmt='g')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                 blocks = [\n\u001b[0;32m-> 1671\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 6, placement implies 5",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1ac3e9b5cf57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"irritated\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disappointed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"neutral\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"happy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"delighted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"irritated\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disappointed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"neutral\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"happy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"delighted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Purples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (6, 6), indices imply (5, 5)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKh_bJxtlhkW"
      },
      "source": [
        "From the above plot we can see that the most confused classes are 'joy' and 'love' which seems obivous as these two emotions are really close. We can say the same thing 'surprise' and 'anger' as well. So our model is doing pretty well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16TiclmeX1xE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ-YLmJyg64T"
      },
      "source": [
        "## SWAG\n",
        "\n",
        "Now lets try a more challenging task and see how it performs.\n",
        "\n",
        "SWAG is a natural language inference and commonsense reasoning task proposed in this [paper](https://arxiv.org/pdf/1808.05326.pdf).\n",
        "\n",
        "The basic task is that  a model is\n",
        "given a context **c = (s, n)**: a complete sentence\n",
        "**s** and a noun phrase **n** that begins a second sentence, as well as a list of possible verb phrase sentence endings **V**. The model must then\n",
        "select the most appropriate verb phrase **v** in **V**. For example\n",
        "\n",
        "On stage, a woman takes a seat at the piano. She\n",
        "\n",
        "a) sits on a bench as her sister plays with the doll.\n",
        "\n",
        "b) smiles with someone as the music plays.\n",
        "\n",
        "c) is in the crowd, watching the dancers.\n",
        "\n",
        "**d) nervously sets her fingers on the keys.**\n",
        "\n",
        "The correct answer is bolded. Given the above example the model should select **nervously sets her fingers on the keys** as the most appropriate verb phrase\n",
        "\n",
        "To frame this task in text-2-text setting the example is processed as below.\n",
        "\n",
        "context: context_text options: 1: option_1 2: option_2 3: option_3 4: option_4\n",
        "\n",
        "and if the actual label is 1 then the model is asked to predict the text '1'. Here's how the above example will be processed\n",
        "\n",
        "**Input**\n",
        "\n",
        "context: On stage, a woman takes a seat at the piano. She  options: 1: sits on a bench as her sister plays with the doll. 2: smiles with someone as the music plays. 3: is in the crowd, watching the dancers. 4: nervously sets her fingers on the keys.\n",
        "\n",
        "**Target**\n",
        "\n",
        "4\n",
        "\n",
        "This is just one possible way to process these examples, there are various other ways we can formulate this problem in text-2-text setting but that's for later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOxk-ZoJmamm"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHfgOhThLPj"
      },
      "source": [
        "import csv\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from enum import Enum\n",
        "from typing import List, Optional\n",
        "from transformers import PreTrainedTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DulV7U5hik7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "880c611b-d11c-4620-9d75-0bcfa423c1ff"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/rowanz/swagaf/master/data/train.csv\n",
        "!wget https://raw.githubusercontent.com/rowanz/swagaf/master/data/val.csv\n",
        "\n",
        "!mkdir swag_data\n",
        "!mv *.csv swag_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-09 15:06:34--  https://raw.githubusercontent.com/rowanz/swagaf/master/data/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28243333 (27M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  26.93M  35.9MB/s    in 0.8s    \n",
            "\n",
            "2020-05-09 15:06:35 (35.9 MB/s) - ‘train.csv’ saved [28243333/28243333]\n",
            "\n",
            "--2020-05-09 15:06:38--  https://raw.githubusercontent.com/rowanz/swagaf/master/data/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7893588 (7.5M) [text/plain]\n",
            "Saving to: ‘val.csv’\n",
            "\n",
            "val.csv             100%[===================>]   7.53M  17.5MB/s    in 0.4s    \n",
            "\n",
            "2020-05-09 15:06:39 (17.5 MB/s) - ‘val.csv’ saved [7893588/7893588]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tllm6irZg8IO"
      },
      "source": [
        "# below code is adapted from https://github.com/huggingface/transformers/blob/master/examples/multiple-choice/utils_multiple_choice.py\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class InputExample:\n",
        "    \"\"\"\n",
        "    A single training/test example for multiple choice\n",
        "    Args:\n",
        "        example_id: Unique id for the example.\n",
        "        question: string. The untokenized text of the second sequence (question).\n",
        "        contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n",
        "        endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    example_id: str\n",
        "    context: str\n",
        "    endings: List[str]\n",
        "    label: Optional[str]\n",
        "\n",
        "class Split(Enum):\n",
        "    train = \"train\"\n",
        "    dev = \"dev\"\n",
        "    test = \"test\"\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class SwagProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the SWAG data set.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        logger.info(\"LOOKING AT {} train\".format(data_dir))\n",
        "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"train.csv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        logger.info(\"LOOKING AT {} dev\".format(data_dir))\n",
        "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"val.csv\")), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        logger.info(\"LOOKING AT {} dev\".format(data_dir))\n",
        "        raise ValueError(\n",
        "            \"For swag testing, the input file does not contain a label column. It can not be tested in current code\"\n",
        "            \"setting!\"\n",
        "        )\n",
        "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"test.csv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\", \"1\", \"2\", \"3\"]\n",
        "\n",
        "    def _read_csv(self, input_file):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            return list(csv.reader(f))\n",
        "\n",
        "    def _create_examples(self, lines: List[List[str]], type: str):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        if type == \"train\" and lines[0][-1] != \"label\":\n",
        "            raise ValueError(\"For training, the input file must contain a label column.\")\n",
        "\n",
        "        examples = [\n",
        "            InputExample(\n",
        "                example_id=line[2],\n",
        "                # common beginning of each\n",
        "                # choice is stored in \"sent2\".\n",
        "                context=line[3],\n",
        "                endings=[line[7], line[8], line[9], line[10]],\n",
        "                label=line[11],\n",
        "            )\n",
        "            for line in lines[1:]  # we skip the line with the column names\n",
        "        ]\n",
        "\n",
        "        return examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OXxGvqZjC9L"
      },
      "source": [
        "class SwagDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
        "    self.data_dir = data_dir\n",
        "    self.type_path = type_path\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self.proc = SwagProcessor()\n",
        "\n",
        "    self._build()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def _build(self):\n",
        "    if self.type_path == 'train':\n",
        "      examples = self.proc.get_train_examples(self.data_dir)\n",
        "    else:\n",
        "      examples = self.proc.get_dev_examples(self.data_dir)\n",
        "    \n",
        "    for example in examples:\n",
        "      self._create_features(example)\n",
        "  \n",
        "  def _create_features(self, example):\n",
        "    input_ = example.context\n",
        "    options = ['%s: %s' % (i, option) for i, option in zip('1234', example.endings)]\n",
        "    options = \" \".join(options)\n",
        "    input_ = \"context: %s  options: %s </s>\" % (input_, options)\n",
        "    target = \"%s </s>\" % str(int(example.label) + 1)\n",
        "\n",
        "    # tokenize inputs\n",
        "    tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "        [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    # tokenize targets\n",
        "    tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "        [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    self.inputs.append(tokenized_inputs)\n",
        "    self.targets.append(tokenized_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKqFMTku3sDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "78b1b91a08214461b74fb1e143247d1e",
            "902a509471004d2691d807c4990fccd2",
            "74ec15497e1743a4af6be12e3bc1487d",
            "a70b457d9379403f9fac247de68bb8e3",
            "28f9d9aa0ece4831b0f9e412d8a88f8d",
            "7640680e1006492da75d873726567fed",
            "1090e3e017564a2281c60fb53a901c75",
            "9df2679ba627444e9b76bd2ff0ddc657"
          ]
        },
        "outputId": "97ce9f8a-4b75-4d95-ba04-fae101f8db82"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140245777042344 acquired on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpv2ybakmg\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78b1b91a08214461b74fb1e143247d1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model in cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n",
            "INFO:filelock:Lock 140245777042344 released on /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f.lock\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIUiU7zSpbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "328b5f15-fe96-43ce-99e9-5d4233a7e97a"
      },
      "source": [
        "dataset = SwagDataset(tokenizer, data_dir='swag_data', type_path='val')\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:LOOKING AT swag_data dev\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxXGbCzB37HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8fbda79c-7be7-4d5f-8d5f-7b986a1c374b"
      },
      "source": [
        "data = dataset[69]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "context: A little girl plays softly the drums holding two sticks while she is singing on a microphone. The, the girl options: 1: take in the greeting and an asian girl followed by two people standing on stage. 2: holds the microphone up and begins to girl dance an entire time. 3: claps the girls hands anxiously. 4: plays more fast the drums.\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVfmE4O3Ku7H"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDPxWUY86llx"
      },
      "source": [
        "!mkdir -p t5_swag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWtMjcj6lmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fe4e58ab-6916-45f9-f742-797d87ad1ef4"
      },
      "source": [
        "args_dict.update({'data_dir': 'swag_data', 'output_dir': 't5_swag', 'num_train_epochs': 3})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data_dir': 'swag_data', 'output_dir': 't5_swag', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_seq_length': 512, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 8, 'eval_batch_size': 8, 'num_train_epochs': 3, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ojz3THj6lmK"
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk0x0Nql6lmQ"
      },
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return SwagDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDFGzzpQ6lmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c7427d7db844b9691d30cf2de1efc17",
            "bb0df1833ee3489da5c2a9c7b1306cc6",
            "3d2817812b6f475a8c838fd14646469a",
            "9d0f0c946790477fb8bc8bac64dfd7de",
            "8254b8062d5e4280bea46f8bc444c5db",
            "ab5f07ab5c574148a0062eb7f1ce5bcd",
            "47fdc2009efc443392ecd182996fcca9",
            "9b705e83fea84cbf912e33d6342be721",
            "e8e8ea6199df43019930ac7b557c46a5",
            "0566f29b017f47f399d7579d7929e046",
            "932309f0a40b46659c0cac7cc37fdc05",
            "da3665141bd44a24a5b5c9f36d4a9c52",
            "5c98e3a5b6a6403a936a725f4c30cdd3",
            "8da2b560fa9348098a2a7f09967d5f5f",
            "7e37cac227014717987922341f8099fe",
            "b95f98f98a76434591f90d41b43e39ba"
          ]
        },
        "outputId": "94aa8d13-9d11-4fa9-979f-e3bbf15bb639"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140242832534944 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpwv74k3ig\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c7427d7db844b9691d30cf2de1efc17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:filelock:Lock 140242832534944 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
            "INFO:transformers.configuration_utils:Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140242971659568 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
            "INFO:transformers.file_utils:https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5pcfx_u3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e8ea6199df43019930ac7b557c46a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
            "INFO:filelock:Lock 140242971659568 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQVILFo63Eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "57300f1a-14a8-4e26-8dac-9238e34741c0"
      },
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:GPU available: True, used: True\n",
            "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STkqK5nC64YP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e79d03deee94b299431330441bd64c8",
            "510043ffee634f86b89ec3fc060a74ea",
            "e86c5fbd48ce4215a0df353122183982",
            "bfc3a5a3cf2e49868053db6f1ef7785d",
            "361a2f79ed89495894d0b09a709f8f32",
            "f7e53d55f0234627a3b9f2c90eb8682f",
            "3584c01b0c5e47dfa373bae29461e94a",
            "cfd9db6f31474a8189e741bf8fdad6a9",
            "68705cee3df5458fb5145046337d925c",
            "4cf1613d58bd450780ac95c994686985",
            "3ee5f7cf56394175900ebb14ae0b5f9e",
            "9f054dcf926c45459b7aa728493571a0",
            "b52599dda9d94c83891d1c42c5f557e0",
            "a1cf907a3bcc4177b1d5dd9edbf30c20",
            "82b29ceeb21c417782e9e29a81eb47ea",
            "886260804ffd4e11bc93fb6e098111ab",
            "69f6eb1cb0434128961b5d83529813c5",
            "6723d50588a248d0ad7bb118de8c3fd5",
            "86d71b8233c14252a897ffa29ea6d9df",
            "d01c708e22ab423896271fa79860e7c3",
            "0e8da5995754472fac5fba1f8b30d107",
            "3dbee77f299f4e14a1698b60d609b8a1",
            "8c4c9025aaae44148591ae6f8bb37347",
            "29e2f2f0914e4dea8117844675b42be5",
            "0cfc8fa73f164b4fa5ddcbc3f115ef9b",
            "4559bd35b33f4804b968debaaf316463",
            "e403cc7718bf48f1b95150482e083f02",
            "f6248a9db7f2466a9ab3a4fbd214f265",
            "475e5353d31147d3ab156c0e7835684c",
            "c3f65d683c6e4fe18e31ecc305f8d455",
            "9b50abad66b44022aa389bc3f312db6b",
            "762b2941ff3e47d89b6e6ce4350bc058"
          ]
        },
        "outputId": "cb613d72-009f-44eb-acd8-b9c3dd44b0cb"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:lightning:\n",
            "    | Name                                                                  | Type                       | Params\n",
            "-----------------------------------------------------------------------------------------------------------------\n",
            "0   | model                                                                 | T5ForConditionalGeneration | 222 M \n",
            "1   | model.shared                                                          | Embedding                  | 24 M  \n",
            "2   | model.encoder                                                         | T5Stack                    | 109 M \n",
            "3   | model.encoder.block                                                   | ModuleList                 | 84 M  \n",
            "4   | model.encoder.block.0                                                 | T5Block                    | 7 M   \n",
            "5   | model.encoder.block.0.layer                                           | ModuleList                 | 7 M   \n",
            "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "22  | model.encoder.block.1                                                 | T5Block                    | 7 M   \n",
            "23  | model.encoder.block.1.layer                                           | ModuleList                 | 7 M   \n",
            "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "39  | model.encoder.block.2                                                 | T5Block                    | 7 M   \n",
            "40  | model.encoder.block.2.layer                                           | ModuleList                 | 7 M   \n",
            "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "56  | model.encoder.block.3                                                 | T5Block                    | 7 M   \n",
            "57  | model.encoder.block.3.layer                                           | ModuleList                 | 7 M   \n",
            "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "73  | model.encoder.block.4                                                 | T5Block                    | 7 M   \n",
            "74  | model.encoder.block.4.layer                                           | ModuleList                 | 7 M   \n",
            "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "90  | model.encoder.block.5                                                 | T5Block                    | 7 M   \n",
            "91  | model.encoder.block.5.layer                                           | ModuleList                 | 7 M   \n",
            "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "107 | model.encoder.block.6                                                 | T5Block                    | 7 M   \n",
            "108 | model.encoder.block.6.layer                                           | ModuleList                 | 7 M   \n",
            "109 | model.encoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "110 | model.encoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "111 | model.encoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "112 | model.encoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "113 | model.encoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "114 | model.encoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "115 | model.encoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "116 | model.encoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "117 | model.encoder.block.6.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "118 | model.encoder.block.6.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "119 | model.encoder.block.6.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "120 | model.encoder.block.6.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "122 | model.encoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "123 | model.encoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "124 | model.encoder.block.7                                                 | T5Block                    | 7 M   \n",
            "125 | model.encoder.block.7.layer                                           | ModuleList                 | 7 M   \n",
            "126 | model.encoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "127 | model.encoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "128 | model.encoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "129 | model.encoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "130 | model.encoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "131 | model.encoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "132 | model.encoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "133 | model.encoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "134 | model.encoder.block.7.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "135 | model.encoder.block.7.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "136 | model.encoder.block.7.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "137 | model.encoder.block.7.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "139 | model.encoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "140 | model.encoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "141 | model.encoder.block.8                                                 | T5Block                    | 7 M   \n",
            "142 | model.encoder.block.8.layer                                           | ModuleList                 | 7 M   \n",
            "143 | model.encoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "144 | model.encoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "145 | model.encoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "146 | model.encoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "147 | model.encoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "148 | model.encoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "149 | model.encoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "150 | model.encoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "151 | model.encoder.block.8.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "152 | model.encoder.block.8.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "153 | model.encoder.block.8.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "154 | model.encoder.block.8.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "156 | model.encoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "157 | model.encoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "158 | model.encoder.block.9                                                 | T5Block                    | 7 M   \n",
            "159 | model.encoder.block.9.layer                                           | ModuleList                 | 7 M   \n",
            "160 | model.encoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "161 | model.encoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "162 | model.encoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "163 | model.encoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "164 | model.encoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "165 | model.encoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "166 | model.encoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "167 | model.encoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "168 | model.encoder.block.9.layer.1                                         | T5LayerFF                  | 4 M   \n",
            "169 | model.encoder.block.9.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "170 | model.encoder.block.9.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "171 | model.encoder.block.9.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "173 | model.encoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "174 | model.encoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "175 | model.encoder.block.10                                                | T5Block                    | 7 M   \n",
            "176 | model.encoder.block.10.layer                                          | ModuleList                 | 7 M   \n",
            "177 | model.encoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "178 | model.encoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "179 | model.encoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "180 | model.encoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "181 | model.encoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "182 | model.encoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "183 | model.encoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "184 | model.encoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "185 | model.encoder.block.10.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "186 | model.encoder.block.10.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "187 | model.encoder.block.10.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "188 | model.encoder.block.10.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "189 | model.encoder.block.10.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "190 | model.encoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "191 | model.encoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "192 | model.encoder.block.11                                                | T5Block                    | 7 M   \n",
            "193 | model.encoder.block.11.layer                                          | ModuleList                 | 7 M   \n",
            "194 | model.encoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "195 | model.encoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "196 | model.encoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "197 | model.encoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "198 | model.encoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "199 | model.encoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "200 | model.encoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "201 | model.encoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "202 | model.encoder.block.11.layer.1                                        | T5LayerFF                  | 4 M   \n",
            "203 | model.encoder.block.11.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "204 | model.encoder.block.11.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "205 | model.encoder.block.11.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "206 | model.encoder.block.11.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "207 | model.encoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "208 | model.encoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "209 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "210 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
            "211 | model.decoder                                                         | T5Stack                    | 137 M \n",
            "212 | model.decoder.block                                                   | ModuleList                 | 113 M \n",
            "213 | model.decoder.block.0                                                 | T5Block                    | 9 M   \n",
            "214 | model.decoder.block.0.layer                                           | ModuleList                 | 9 M   \n",
            "215 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "216 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "217 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "218 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "219 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "220 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
            "222 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "223 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
            "224 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "225 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "226 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "227 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "228 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "229 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "230 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 384   \n",
            "231 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "232 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
            "233 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "234 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "235 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "236 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "237 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "238 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "239 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
            "240 | model.decoder.block.1                                                 | T5Block                    | 9 M   \n",
            "241 | model.decoder.block.1.layer                                           | ModuleList                 | 9 M   \n",
            "242 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "243 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "244 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "245 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "246 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "247 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "248 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "249 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
            "250 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "251 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "252 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "253 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "254 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "255 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "256 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "257 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
            "258 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "259 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "260 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "261 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "262 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "263 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "264 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
            "265 | model.decoder.block.2                                                 | T5Block                    | 9 M   \n",
            "266 | model.decoder.block.2.layer                                           | ModuleList                 | 9 M   \n",
            "267 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "268 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "269 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "270 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "271 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "272 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "273 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "274 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
            "275 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "276 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "277 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "278 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "279 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "280 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "281 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "282 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
            "283 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "284 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "285 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "286 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "287 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "288 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "289 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
            "290 | model.decoder.block.3                                                 | T5Block                    | 9 M   \n",
            "291 | model.decoder.block.3.layer                                           | ModuleList                 | 9 M   \n",
            "292 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "293 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "294 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "295 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "296 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "297 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "298 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "299 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
            "300 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "301 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "302 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "303 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "304 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "305 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "306 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "307 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
            "308 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "309 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "310 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "311 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "312 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "313 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "314 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
            "315 | model.decoder.block.4                                                 | T5Block                    | 9 M   \n",
            "316 | model.decoder.block.4.layer                                           | ModuleList                 | 9 M   \n",
            "317 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "318 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "319 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "320 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "321 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "322 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "323 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "324 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
            "325 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "326 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "327 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "328 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "329 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "330 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "331 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "332 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
            "333 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "334 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "335 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "336 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "337 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "338 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "339 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
            "340 | model.decoder.block.5                                                 | T5Block                    | 9 M   \n",
            "341 | model.decoder.block.5.layer                                           | ModuleList                 | 9 M   \n",
            "342 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "343 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "344 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "345 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "346 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "347 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "348 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "349 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
            "350 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "351 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "352 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "353 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "354 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "355 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "356 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "357 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
            "358 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "359 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "360 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "361 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "362 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "363 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "364 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
            "365 | model.decoder.block.6                                                 | T5Block                    | 9 M   \n",
            "366 | model.decoder.block.6.layer                                           | ModuleList                 | 9 M   \n",
            "367 | model.decoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "368 | model.decoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "369 | model.decoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "370 | model.decoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "371 | model.decoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "372 | model.decoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "373 | model.decoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "374 | model.decoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
            "375 | model.decoder.block.6.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "376 | model.decoder.block.6.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "377 | model.decoder.block.6.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "378 | model.decoder.block.6.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "379 | model.decoder.block.6.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "380 | model.decoder.block.6.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "381 | model.decoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "382 | model.decoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
            "383 | model.decoder.block.6.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "384 | model.decoder.block.6.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "385 | model.decoder.block.6.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "386 | model.decoder.block.6.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "387 | model.decoder.block.6.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "388 | model.decoder.block.6.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "389 | model.decoder.block.6.layer.2.dropout                                 | Dropout                    | 0     \n",
            "390 | model.decoder.block.7                                                 | T5Block                    | 9 M   \n",
            "391 | model.decoder.block.7.layer                                           | ModuleList                 | 9 M   \n",
            "392 | model.decoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "393 | model.decoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "394 | model.decoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "395 | model.decoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "396 | model.decoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "397 | model.decoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "398 | model.decoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "399 | model.decoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
            "400 | model.decoder.block.7.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "401 | model.decoder.block.7.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "402 | model.decoder.block.7.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "403 | model.decoder.block.7.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "404 | model.decoder.block.7.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "405 | model.decoder.block.7.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "406 | model.decoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "407 | model.decoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
            "408 | model.decoder.block.7.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "409 | model.decoder.block.7.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "410 | model.decoder.block.7.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "411 | model.decoder.block.7.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "412 | model.decoder.block.7.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "413 | model.decoder.block.7.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "414 | model.decoder.block.7.layer.2.dropout                                 | Dropout                    | 0     \n",
            "415 | model.decoder.block.8                                                 | T5Block                    | 9 M   \n",
            "416 | model.decoder.block.8.layer                                           | ModuleList                 | 9 M   \n",
            "417 | model.decoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "418 | model.decoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "419 | model.decoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "420 | model.decoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "421 | model.decoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "422 | model.decoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "423 | model.decoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "424 | model.decoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
            "425 | model.decoder.block.8.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "426 | model.decoder.block.8.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "427 | model.decoder.block.8.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "428 | model.decoder.block.8.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "429 | model.decoder.block.8.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "430 | model.decoder.block.8.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "431 | model.decoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "432 | model.decoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
            "433 | model.decoder.block.8.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "434 | model.decoder.block.8.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "435 | model.decoder.block.8.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "436 | model.decoder.block.8.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "437 | model.decoder.block.8.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "438 | model.decoder.block.8.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "439 | model.decoder.block.8.layer.2.dropout                                 | Dropout                    | 0     \n",
            "440 | model.decoder.block.9                                                 | T5Block                    | 9 M   \n",
            "441 | model.decoder.block.9.layer                                           | ModuleList                 | 9 M   \n",
            "442 | model.decoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
            "443 | model.decoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
            "444 | model.decoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
            "445 | model.decoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
            "446 | model.decoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
            "447 | model.decoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
            "448 | model.decoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
            "449 | model.decoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
            "450 | model.decoder.block.9.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
            "451 | model.decoder.block.9.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
            "452 | model.decoder.block.9.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
            "453 | model.decoder.block.9.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
            "454 | model.decoder.block.9.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
            "455 | model.decoder.block.9.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
            "456 | model.decoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
            "457 | model.decoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
            "458 | model.decoder.block.9.layer.2                                         | T5LayerFF                  | 4 M   \n",
            "459 | model.decoder.block.9.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
            "460 | model.decoder.block.9.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
            "461 | model.decoder.block.9.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
            "462 | model.decoder.block.9.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
            "463 | model.decoder.block.9.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
            "464 | model.decoder.block.9.layer.2.dropout                                 | Dropout                    | 0     \n",
            "465 | model.decoder.block.10                                                | T5Block                    | 9 M   \n",
            "466 | model.decoder.block.10.layer                                          | ModuleList                 | 9 M   \n",
            "467 | model.decoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "468 | model.decoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "469 | model.decoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "470 | model.decoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "471 | model.decoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "472 | model.decoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "473 | model.decoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "474 | model.decoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
            "475 | model.decoder.block.10.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "476 | model.decoder.block.10.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "477 | model.decoder.block.10.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "478 | model.decoder.block.10.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "479 | model.decoder.block.10.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "480 | model.decoder.block.10.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "481 | model.decoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "482 | model.decoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
            "483 | model.decoder.block.10.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "484 | model.decoder.block.10.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "485 | model.decoder.block.10.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "486 | model.decoder.block.10.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "487 | model.decoder.block.10.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "488 | model.decoder.block.10.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "489 | model.decoder.block.10.layer.2.dropout                                | Dropout                    | 0     \n",
            "490 | model.decoder.block.11                                                | T5Block                    | 9 M   \n",
            "491 | model.decoder.block.11.layer                                          | ModuleList                 | 9 M   \n",
            "492 | model.decoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
            "493 | model.decoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
            "494 | model.decoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
            "495 | model.decoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
            "496 | model.decoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
            "497 | model.decoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
            "498 | model.decoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
            "499 | model.decoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
            "500 | model.decoder.block.11.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
            "501 | model.decoder.block.11.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
            "502 | model.decoder.block.11.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
            "503 | model.decoder.block.11.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
            "504 | model.decoder.block.11.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
            "505 | model.decoder.block.11.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
            "506 | model.decoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
            "507 | model.decoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
            "508 | model.decoder.block.11.layer.2                                        | T5LayerFF                  | 4 M   \n",
            "509 | model.decoder.block.11.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
            "510 | model.decoder.block.11.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
            "511 | model.decoder.block.11.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
            "512 | model.decoder.block.11.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
            "513 | model.decoder.block.11.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
            "514 | model.decoder.block.11.layer.2.dropout                                | Dropout                    | 0     \n",
            "515 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
            "516 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
            "517 | model.lm_head                                                         | Linear                     | 24 M  \n",
            "INFO:__main__:LOOKING AT swag_data dev\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e79d03deee94b299431330441bd64c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:LOOKING AT swag_data train\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:LOOKING AT swag_data dev\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68705cee3df5458fb5145046337d925c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69f6eb1cb0434128961b5d83529813c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_val_loss = tensor(0.3535, device='cuda:0')\n",
            "\n",
            "INFO:__main__:loss = tensor(0.3080, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.3080, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.3535, device='cuda:0')\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cfc8fa73f164b4fa5ddcbc3f115ef9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:***** Validation results *****\n",
            "INFO:__main__:avg_train_loss = tensor(0.5107, device='cuda:0')\n",
            "\n",
            "INFO:__main__:avg_val_loss = tensor(0.3268, device='cuda:0')\n",
            "\n",
            "INFO:__main__:epoch = 0\n",
            "\n",
            "INFO:__main__:loss = tensor(0.5484, device='cuda:0')\n",
            "\n",
            "INFO:__main__:train_loss = tensor(0.5484, device='cuda:0')\n",
            "\n",
            "INFO:__main__:val_loss = tensor(0.3268, device='cuda:0')\n",
            "\n",
            "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ZB_6SK7V-3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgNV3TMzqSvj"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFFOwfXyqc4_"
      },
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsYCq3Lwqc5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51f7bd88-2441-42be-e8f3-adc0337a164c"
      },
      "source": [
        "dataset =  SwagDataset(tokenizer, data_dir='swag_data', type_path='val')\n",
        "loader = DataLoader(dataset, batch_size=32, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:LOOKING AT swag_data dev\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHwMBQNjqc5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1597779d89464892885045be715890a8",
            "8a42468ed6b945e8bfce1803f3ea4452",
            "f87eae824cf1492b9555b78648a9f261",
            "6cd0d574b5fd43588b8d492674125218",
            "17b25142ac744ba882e2bbd1f42c1db2",
            "09185d325ef84c1fad7b07fbd9eeed31",
            "ba31765789dc46229493674dab21921d",
            "a9dd88fb73374e108482b80993b998eb"
          ]
        },
        "outputId": "81e7d67d-1d15-4dea-a552-695cfe8ef105"
      },
      "source": [
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1597779d89464892885045be715890a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=626.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbTValmYq15r"
      },
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in \"1234\":\n",
        "    print(i, 'detected invalid prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN35n2pas-pF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be8a3507-8e66-479d-c41c-dd9cb0603742"
      },
      "source": [
        "metrics.accuracy_score(targets, outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7397280815755274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_WaMutznvGb"
      },
      "source": [
        "This is great! We have achieved almost 74% accuracy with this simple formulation. This is great becuase with BERT like models to make a prediction on single example the model needs to do 4 forward passes, one for each possible endings and then the logits are concatenated together for all 4 passes and then passed through final softmax layer to produce 4 probabilities. This approach needs only a single pass for one example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFgOHlW_tHPd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}